{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2424ed0-4ebc-4c6d-bff7-beaffeea95d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow verions: 2.4.0\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras import ops\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph, IndexedArray\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from stellargraph.mapper import AdjacencyPowerGenerator\n",
    "from stellargraph.layer import WatchYourStep\n",
    "from stellargraph import datasets, utils\n",
    "from tensorflow.keras import callbacks, optimizers, losses, metrics, regularizers, Model\n",
    "\n",
    "from stellargraph.mapper import KGTripleGenerator\n",
    "from stellargraph.layer import ComplEx\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from graph_visualization import GraphVisualization\n",
    "\n",
    "print(\"Tensorflow verions:\", tf.__version__)\n",
    "print('Available GPUs:', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93b860e0-b6d6-49cc-8275-1d6b9beeb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Mask the upper half of the dot product matrix in self attention.\n",
    "    This prevents flow of information from future tokens to current token.\n",
    "    1's in the lower triangle, counting from the lower right corner.\n",
    "    \"\"\"\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, \"bool\")\n",
    "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return [self.att.get_weights(), self.ffn.layers[0].get_weights(), self.ffn.layers[1].get_weights()]\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.att.set_weights(weights[0])\n",
    "        self.ffn.layers[0].set_weights(weights[1])\n",
    "        self.ffn.layers[1].set_weights(weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "a0ae20fa-e191-4b5f-92e7-7fd3d05d971b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 files\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30  # Only consider the top 20k words\n",
    "maxlen = 10  # Max sequence size\n",
    "batch_size = 128\n",
    "\n",
    "# The dataset contains each review in a separate text file\n",
    "# The text files are present in four different folders\n",
    "# Create a list all files\n",
    "filenames = []\n",
    "directories = [\n",
    "    \"gpt-dataset/custom-2.6\"\n",
    "]\n",
    "for dir in directories:\n",
    "    for f in os.listdir(dir):\n",
    "        filenames.append(os.path.join(dir, f))\n",
    "\n",
    "# filenames = filenames[:10000]\n",
    "\n",
    "print(f\"{len(filenames)} files\")\n",
    "\n",
    "# Create a dataset from text files\n",
    "random.shuffle(filenames)\n",
    "text_ds = tf_data.TextLineDataset(filenames)\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"Remove html line-break tags and handle punctuation\"\"\"\n",
    "    lowercased = tf_strings.lower(input_string)\n",
    "    stripped_html = tf_strings.regex_replace(lowercased, \"<br />\", \" \")\n",
    "    return tf_strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n",
    "\n",
    "\n",
    "# Create a vectorization layer and adapt it to the text\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=maxlen + 1,\n",
    ")\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def count_occurences(text_ds):\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Custom text preprocessing\n",
    "        # For example, you can perform lowercasing, punctuation removal, etc.\n",
    "        return text.lower()\n",
    "    \n",
    "    # Preprocess the text data and convert it to a list\n",
    "    preprocessed_texts = [preprocess_text(str(text.numpy())) for text in text_ds]\n",
    "    # Initialize CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    # Fit CountVectorizer on preprocessed text data and transform it into token counts\n",
    "    token_counts = vectorizer.fit_transform(preprocessed_texts)\n",
    "    # Get the vocabulary and token counts\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    counts = token_counts.toarray().sum(axis=0)\n",
    "    # Create a dictionary to store token counts\n",
    "    token_counts_dict = dict(zip(vocab, counts))\n",
    "\n",
    "    token_counts_dict = sorted(token_counts_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    print(token_counts_dict)\n",
    "\n",
    "# count_occurences(text_ds)\n",
    "\n",
    "def filter_dataset(line):\n",
    "    return not tf.strings.regex_full_match(line, \".*\\\\bpiano\\\\b.*\")\n",
    "\n",
    "text_ds = text_ds.filter(lambda line: filter_dataset(line))\n",
    "\n",
    "text_ds = text_ds.shuffle(buffer_size=256)\n",
    "text_ds = text_ds.batch(batch_size)\n",
    "\n",
    "# for text in text_ds:\n",
    "#     print(str(text.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "2d95d8db-170b-4421-b463-760d5355fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 10), (None, 10)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_lm_inputs_labels(text):\n",
    "    \"\"\"\n",
    "    Shift word sequences by 1 position so that the target for position (i) is\n",
    "    word at position (i+1). The model will use all words up till position (i)\n",
    "    to predict the next word.\n",
    "    \"\"\"\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "\n",
    "    # zeros_column = tf.zeros_like(y[:, :1])  # Create a column of zeros with the same shape as the first column of y\n",
    "    # y = tf.concat([zeros_column, y], axis=1)  # Concatenate the zeros column with y along the column axis\n",
    "\n",
    "    return x, y\n",
    "\n",
    "text_ds = text_ds.map(prepare_lm_inputs_labels, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "text_ds = text_ds.prefetch(tf_data.AUTOTUNE)\n",
    "\n",
    "def prepare_node_vector_outputs(text_ds, node_embeddings):\n",
    "    def process(x,y):\n",
    "        return x, (y, tf.gather(node_embeddings, y))\n",
    "        \n",
    "    return text_ds.map(process, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "\n",
    "# text_ds = prepare_node_vector_outputs(text_ds, final_embeddings)\n",
    "# text_ds = text_ds.prefetch(tf_data.AUTOTUNE)\n",
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046753c0-b525-48c4-9b59-b6e6e5948c5c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sources = ['guitar', 'guitar', 'guitar', 'violin', 'violin', 'violin', 'piano', 'piano', 'piano', \n",
    "           'car', 'car', 'car', 'truck', 'truck', 'truck', 'neck', 'strings', 'keys', 'pedals', \n",
    "           'wheels', 'baggage', 'trunk', 'instrument', 'vehicle', 'trombone', 'trombone', 'trombone', 'bell', 'slide']\n",
    "labels = ['is', 'has', 'has', 'is', 'has', 'has', 'is', 'has', 'has', 'is', 'has', 'has', 'is',\n",
    "          'has', 'has', 'is', 'is', 'is', 'is', 'is', 'is', 'is', 'has', 'has', 'is', 'has', 'has', 'is', 'is']\n",
    "targets = ['instrument', 'neck', 'strings', 'instrument', 'neck', 'strings', 'instrument', 'keys', \n",
    "           'pedals', 'vehicle', 'wheels', 'baggage', 'vehicle', 'wheels', 'trunk', 'part', 'part', \n",
    "           'part', 'part', 'part', 'part', 'part', 'part', 'part', 'instrument', 'bell', 'slide', 'part', 'part']\n",
    "\n",
    "sources.extend(['organ', 'organ', 'organ'])\n",
    "labels.extend(['is', 'has', 'has'])\n",
    "targets.extend(['instrument', 'keys', 'pedals'])\n",
    "\n",
    "graph_data = pd.DataFrame({'source': sources, 'label': labels, 'target': targets})\n",
    "\n",
    "rel_graphs = {}\n",
    "for index, row in graph_data.iterrows():\n",
    "    df = rel_graphs.get(row['label'], pd.DataFrame({'source': [], 'label': [], 'target': []}))\n",
    "    df = df.append({'source': row['source'], 'label': row['label'], 'target': row['target']}, ignore_index=True)\n",
    "    rel_graphs[row['label']] = df\n",
    "    \n",
    "# graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96655133-7e51-43fd-a1a6-ac4abcc7d9ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_embedding_size = 10\n",
    "\n",
    "def node2vec(G):\n",
    "        walk_length = 100\n",
    "        rw = BiasedRandomWalk(G)\n",
    "        walks = rw.run(\n",
    "            nodes=G.nodes(),  # root nodes\n",
    "            length=walk_length,  # maximum length of a random walk\n",
    "            n=10,  # number of random walks per root node\n",
    "            p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "            q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "            weighted=False,  # for weighted random walks\n",
    "            seed=42,  # random seed fixed for reproducibility\n",
    "        )\n",
    "\n",
    "        model = Word2Vec(\n",
    "            walks,  vector_size=graph_embedding_size, window=5, min_count=0, sg=1, workers=1\n",
    "        )\n",
    "\n",
    "        return pd.DataFrame([(key, vector) for key,vector in zip(model.wv.index_to_key, model.wv.vectors)], columns=['node', 'embedding'])\n",
    "\n",
    "def fill_graph(graph, vocab):\n",
    "    for word in vocab:\n",
    "        graph['nodes'].append(word) if word not in graph['nodes'] else None\n",
    "\n",
    "    return graph\n",
    "    \n",
    "def get_graph(graph_data):\n",
    "    nodes, edges, edge_types = [], [], []\n",
    "\n",
    "    for word in graph_data['source'].unique():\n",
    "        nodes.append(word)\n",
    "\n",
    "    for word in graph_data['target'].unique():\n",
    "        nodes.append(word) if word not in nodes else None\n",
    "\n",
    "    for index, row in graph_data.iterrows():\n",
    "        edges.append({'source': row['source'], 'target': row['target']})\n",
    "        edge_types.append(row['label'])\n",
    "\n",
    "    graph = {'nodes':nodes, 'edges': edges, 'edge_types': edge_types}\n",
    "\n",
    "    graph = fill_graph(graph, vocab)\n",
    "    \n",
    "    edges_ = pd.DataFrame({\n",
    "            'source': [e['source'] for e in graph['edges']],\n",
    "            'target': [e['target'] for e in graph['edges']],\n",
    "            'type': graph['edge_types']\n",
    "        })\n",
    "\n",
    "    G = StellarGraph(IndexedArray(index=graph['nodes']), edges_, edge_type_column=\"type\")\n",
    "    \n",
    "    return graph, G\n",
    "\n",
    "def get_embeddings(G):\n",
    "    node_embeddings = complex_embeddings(G, conceptnet_data[['source','label','target']])\n",
    "        \n",
    "    return node_embeddings\n",
    "    \n",
    "graph, G = get_graph(graph_data)\n",
    "full_embeddings = node2vec(G)\n",
    "\n",
    "tmp = []\n",
    "for i,word in enumerate(vocab):\n",
    "    lower_nodes = list(map(lambda k: k.lower(), full_embeddings['node']))\n",
    "    index = lower_nodes.index(word.lower()) if word.lower() in lower_nodes else -1\n",
    "    if index != -1:\n",
    "        tmp.append(full_embeddings.iloc[index][1])\n",
    "    else:\n",
    "        tmp.append(np.ones(graph_embedding_size) * -10)\n",
    "\n",
    "full_embeddings = np.array(tmp)\n",
    "\n",
    "graphs, node_embeddings = [], []\n",
    "for key, _graph_data in rel_graphs.items():\n",
    "    _graph, G = get_graph(_graph_data)\n",
    "    graphs.append(_graph)\n",
    "    node_embeddings.append(node2vec(G))\n",
    "\n",
    "for j, emb in enumerate(node_embeddings):\n",
    "    tmp = []\n",
    "    lower_nodes = list(map(lambda k: k.lower(), emb['node']))\n",
    "    for i,word in enumerate(vocab):\n",
    "        index = lower_nodes.index(word.lower()) if word.lower() in lower_nodes else -1\n",
    "        if index != -1:\n",
    "            tmp.append(emb.iloc[index][1])\n",
    "        else:\n",
    "            tmp.append(np.ones(graph_embedding_size) * -10)\n",
    "    \n",
    "    node_embeddings[j] = np.array(tmp).tolist()\n",
    "\n",
    "node_embeddings = np.array(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81deed0a-d102-43b0-a6b8-2410723048d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings = None\n",
    "for i in range(0, node_embeddings.shape[0] - 1):\n",
    "    embeddings =  np.concatenate((node_embeddings[i], node_embeddings[i + 1]), axis=1)\n",
    "    final_embeddings = embeddings if not final_embeddings else np.concatenate((final_embeddings, embeddings), axis = 1) \n",
    "\n",
    "# final_embeddings = node_embeddings[0]\n",
    "# final_embeddings = node_embeddings[0]\n",
    "# final_embeddings = np.concatenate((final_embeddings, full_embeddings), axis=1)\n",
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c32efc5-96d2-44e4-8816-76e0efb7fae9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "_graph = graph\n",
    "# _graph = graphs[0]\n",
    "index = 0\n",
    "vis = GraphVisualization()\n",
    "for edge in _graph['edges'][index:]:\n",
    "    vis.addEdge(edge['source'], edge['target'])\n",
    "# vis.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b6dd4d40-79b8-4a82-9202-3b172a79bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(A,B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    \"\"\"Calculate the Euclidean distance between two vectors.\"\"\"\n",
    "    # Ensure both vectors are NumPy arrays\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    \n",
    "    # Calculate the squared differences between corresponding elements\n",
    "    squared_diff = np.square(vector1 - vector2)\n",
    "    \n",
    "    # Sum the squared differences and take the square root\n",
    "    distance = np.sqrt(np.sum(squared_diff))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a45ad26-9e27-4006-877c-2a722c625092",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# index_A = vocab.index('guitar')\n",
    "# index_B = vocab.index('neck')\n",
    "# index_C = vocab.index('piano')\n",
    "# index_D = vocab.index('keys')\n",
    "# index_E = vocab.index('trombone')\n",
    "# index_F = vocab.index('bell')\n",
    "# index_G = vocab.index('instrument')\n",
    "\n",
    "# embeddings = node_embeddings[0]\n",
    "# # embeddings = final_embeddings\n",
    "# A,B,C,D,E,F,G = embeddings[index_A], embeddings[index_B], embeddings[index_C], embeddings[index_D], embeddings[index_E], embeddings[index_F], embeddings[index_G]\n",
    "# print('Cosine Similarities: ')\n",
    "# print('A, B: ', cosine_sim(A,B), '\\nA, C: ', cosine_sim(A,C), '\\nA, D: ', cosine_sim(A,D), \n",
    "#       '\\nB, C: ',cosine_sim(B,C), '\\nB, D: ', cosine_sim(B,D), '\\nC, D: ', cosine_sim(C,D),\n",
    "#       '\\nA, E: ',cosine_sim(A,E), '\\nB, E: ', cosine_sim(B,E), '\\nE, F: ', cosine_sim(E,F),\n",
    "#       '\\nC, F: ',cosine_sim(C,F), '\\nD, F: ', cosine_sim(D,F), '\\nA, G: ', cosine_sim(A,G),\n",
    "#       '\\nB, G: ', cosine_sim(B,G), '\\nE, G: ', cosine_sim(E,G))\n",
    "# print('Euclidean Distances: ')\n",
    "# print('A, B: ', euclidean_distance(A,B), '\\nA, C: ', euclidean_distance(A,C), '\\nA, D: ', euclidean_distance(A,D), \n",
    "#       '\\nB, C: ',euclidean_distance(B,C), '\\nB, D: ', euclidean_distance(B,D), '\\nC, D: ', euclidean_distance(C,D),\n",
    "#       '\\nA, E: ',euclidean_distance(A,E), '\\nB, E: ', euclidean_distance(B,E), '\\nE, F: ', euclidean_distance(E,F),\n",
    "#       '\\nC, F: ',euclidean_distance(C,F), '\\nD, F: ', euclidean_distance(D,F), '\\nA, G: ', euclidean_distance(A,G),\n",
    "#       '\\nB, G: ', euclidean_distance(B,G), '\\nC, G: ', euclidean_distance(C,G), '\\nD, G: ', euclidean_distance(D,G),\n",
    "#       '\\nE, G: ', euclidean_distance(E,G), '\\nF, G: ', euclidean_distance(F,G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8823209-4d3f-4a41-978a-3de62eabef51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [(word, emb) for word, emb in zip(vocab, final_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ffa7b441-9e76-41c3-af92-55bc9c7b1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate text from a trained model.\n",
    "    1. Feed some starting prompt to the model\n",
    "    2. Predict probabilities for the next token\n",
    "    3. Sample the next token and add it to the next input\n",
    "\n",
    "    Arguments:\n",
    "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
    "        start_tokens: List of integers, the token indices for the starting prompt.\n",
    "        index_to_word: List of strings, obtained from the TextVectorization layer.\n",
    "        top_k: Integer, sample from the `top_k` token predictions.\n",
    "        print_every: Integer, print after this many epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, max_tokens, start_tokens, index_to_word, node_embeddings, model = None, top_k=10, print_every=1, method='euclidean'\n",
    "    ):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.start_tokens = start_tokens\n",
    "        self.index_to_word = index_to_word\n",
    "        self.print_every = print_every\n",
    "        self.k = top_k\n",
    "        if model: self.model = model\n",
    "        self.yes_count = 0\n",
    "        self.no_count = 0\n",
    "        self.activation_outputs = []\n",
    "        self.gradients = []\n",
    "        self.node_embeddings = node_embeddings\n",
    "        self.normalized_node_embeddings = tf.nn.l2_normalize(tf.constant(node_embeddings, dtype=tf.float32), axis=1)\n",
    "        self.method = method\n",
    "\n",
    "    def sample_from(self, logits, graph_preds):\n",
    "        preds = tf.keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = tf.convert_to_tensor(preds, dtype=tf.float32)\n",
    "        preds = (preds[tf.newaxis,:] + graph_preds[tf.newaxis,:]) / 2.0\n",
    "\n",
    "        preds, indices = tf.math.top_k(preds, k=self.k, sorted=True)\n",
    "        indices = tf.convert_to_tensor(indices, dtype=tf.int32)\n",
    "\n",
    "        # Sample from the softmax probabilities\n",
    "        sampled_index = tf.random.categorical(tf.math.log(preds), num_samples=1)\n",
    "\n",
    "        # Return the sampled index\n",
    "        return indices[sampled_index[0, 0]][0]\n",
    "\n",
    "    def euclidean_distance(self, y):\n",
    "        t_1 = tf.cast(self.node_embeddings, dtype=tf.float32)\n",
    "        t_2 = tf.cast(tf.tile(tf.expand_dims(y,0), [self.node_embeddings.shape[0], 1]), dtype=tf.float32)\n",
    "        squared_diff = tf.square(t_1 - t_2)\n",
    "        \n",
    "        # Sum the squared differences along the appropriate axis\n",
    "        distances = tf.sqrt(tf.reduce_sum(squared_diff, axis=-1))\n",
    "        distances =  tf.transpose(distances) \n",
    "        distances = tf.keras.activations.softmax(tf.expand_dims(tf.negative(tf.square(distances)),0))[0]\n",
    "        distances = tf.pad(distances, [[0, vocab_size - distances.shape[0]]], constant_values=-1)\n",
    "        return distances\n",
    "\n",
    "    def extract_token(self, y_0, y_1):\n",
    "        negative_softmax_distances = self.euclidean_distance(y_1)\n",
    "\n",
    "        return self.sample_from(y_0, negative_softmax_distances)\n",
    "\n",
    "    def detokenize(self, number):\n",
    "        return self.index_to_word[number] if number < len(self.index_to_word) else '---'\n",
    "    \n",
    "    def generate_token(self, start_tokens, tokens_generated):\n",
    "        pad_len = maxlen - len(start_tokens)\n",
    "        sample_index = len(start_tokens) - 1\n",
    "        if pad_len < 0:\n",
    "            x = start_tokens[:maxlen]\n",
    "            sample_index = maxlen - 1\n",
    "        elif pad_len > 0:\n",
    "            x = start_tokens + [0] * pad_len\n",
    "        else:\n",
    "            x = start_tokens\n",
    "        x = np.array([x])\n",
    "        y_0, y_1 = self.model.predict(x, verbose=0)\n",
    "        sample_token = self.extract_token(y_0[0][sample_index], y_1[0][sample_index])\n",
    "        tokens_generated.append(sample_token)\n",
    "        start_tokens.append(sample_token)\n",
    "        num_tokens_generated = len(tokens_generated)\n",
    "\n",
    "        return start_tokens, tokens_generated, num_tokens_generated, (y_0, y_1)\n",
    "\n",
    "    def get_generated_text(self, tokens_generated):\n",
    "        return \" \".join(\n",
    "            [self.detokenize(_) for _ in tokens_generated])\n",
    "        \n",
    "    def get_text(self, tokens_generated):\n",
    "        return \" \".join(\n",
    "            [self.detokenize(_) for _ in self.start_tokens + tokens_generated])\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        start_tokens = [_ for _ in self.start_tokens]\n",
    "        if (epoch + 1) % self.print_every != 0:\n",
    "            return\n",
    "        num_tokens_generated = 0\n",
    "        tokens_generated = []\n",
    "        raw_outputs = []\n",
    "        while num_tokens_generated <= self.max_tokens:\n",
    "            start_tokens, tokens_generated, num_tokens_generated, raw_output = self.generate_token(start_tokens, tokens_generated)\n",
    "            raw_outputs.append(raw_output)\n",
    "            \n",
    "        txt = self.get_text(tokens_generated)\n",
    "        print(f\"generated text:\\n{txt}\\n\")\n",
    "\n",
    "        self.yes_count += 1 if 'yes' in txt else 0\n",
    "        self.no_count += 1 if 'no' in txt else 0\n",
    "\n",
    "        return txt, raw_outputs\n",
    "    \n",
    "    def generate(self):\n",
    "        return self.on_epoc_end(1)\n",
    "\n",
    "# Tokenize starting prompt\n",
    "word_to_index = {}\n",
    "for index, word in enumerate(vocab):\n",
    "    word_to_index[word] = index\n",
    "\n",
    "def callback(start_prompt, model=None, top_k=10, method='euclidean'):\n",
    "    start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n",
    "    num_tokens_generated = 10\n",
    "    return TextGenerator(num_tokens_generated, start_tokens, vocab, final_embeddings, top_k=top_k, method=method) if not model else TextGenerator(num_tokens_generated, start_tokens, vocab, final_embeddings, model, top_k, method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "643dd0da-acfd-4966-aa28-9841f6395271",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]  # Modified line\n",
    "        positions = tf.range(0, maxlen, 1)  # Modified line\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7146048c-63e5-4c02-956a-9990a8c75fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbedding(layers.Layer):\n",
    "    def __init__(self, node_embed_dim, node_embeddings, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_embeddings = tf.constant(node_embeddings, dtype=tf.float32)\n",
    "        self.dense = layers.Dense(node_embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "         # Reshape x to add a new dimension for embedding\n",
    "        node_indices = tf.cast(tf.math.round(x), tf.int32)\n",
    "        node_emb = tf.gather(self.node_embeddings, node_indices)\n",
    "        node_emb = self.dense(node_emb)  # Apply dense layer to each token embedding\n",
    "        return node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "438c2857-3d48-47f8-8d29-8462a7f98760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbeddingTransformation(layers.Layer):\n",
    "    def __init__(self, node_embeddings, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_embeddings = tf.constant(node_embeddings, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        t_1 = tf.cast(tf.tile(tf.expand_dims(tf.expand_dims(self.node_embeddings, [0]), [2]), [tf.shape(x)[0], 1, tf.shape(x)[1], 1]), dtype=tf.float32)\n",
    "        t_2 = tf.cast(tf.tile(tf.expand_dims(x,1), [1, tf.shape(t_1)[1], 1, 1]), dtype=tf.float32)\n",
    "        squared_diff = tf.square(t_1 - t_2)\n",
    "        distances = tf.sqrt(tf.reduce_sum(squared_diff, axis=-1))\n",
    "        distances =  tf.transpose(distances)\n",
    "        distances = tf.negative(distances)\n",
    "        distances = tf.nn.softmax(distances, axis=-1)\n",
    "        distances = tf.transpose(distances, perm=[2,0,1])\n",
    "        distances = tf.pad(distances, [[0,0], [0,0], [0, vocab_size - tf.shape(distances)[-1]]])\n",
    "        \n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5af58a34-a923-4537-86f7-b8da57329978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedOutput(layers.Layer):\n",
    "    def __init__(self, node_embeddings, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_embeddings = node_embeddings\n",
    "        self.dense = layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, text_output, graph_output):\n",
    "        # print(text_output.shape)\n",
    "        # print(graph_output.shape)\n",
    "        # t_1 = tf.cast(tf.tile(tf.expand_dims(tf.expand_dims(self.node_embeddings, [0]), [2]), [tf.shape(graph_output)[0], 1, tf.shape(graph_output)[1], 1]), dtype=tf.float32)\n",
    "        # t_2 = tf.cast(tf.tile(tf.expand_dims(graph_output,1), [1, tf.shape(t_1)[1], 1, 1]), dtype=tf.float32)\n",
    "        # squared_diff = tf.square(t_1 - t_2)\n",
    "        # distances = tf.sqrt(tf.reduce_sum(squared_diff, axis=-1))\n",
    "        # distances =  tf.transpose(distances) \n",
    "        # distances = tf.nn.softmax(distances, axis=-1)\n",
    "        # distances = tf.transpose(distances, perm=[2,0,1])\n",
    "        # distances = tf.pad(distances, [[0,0], [0,0], [0, vocab_size - tf.shape(distances)[-1]]])\n",
    "\n",
    "        # text_output = tf.nn.softmax(text_output, axis=-1)\n",
    "        \n",
    "        return self.dense(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5bffb5b8-3ee3-406f-83aa-4780955d4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "55a846ea-5ac4-4567-87ec-f8fa941def77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "node_embedding_layer (NodeEmbed (None, 10, 256)      5376        input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (TokenAndPositi (None, 10, 256)      10240       input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "node_transformer_layer (Transfo (None, 10, 256)      658688      node_embedding_layer[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "transformer_layer (TransformerB (None, 10, 256)      658688      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "graph_embedding_output (Dense)  (None, 10, 20)       5140        node_transformer_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "text_output (Dense)             (None, 10, 30)       7710        transformer_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "node_embedding_transformation_3 (None, 10, None)     0           graph_embedding_output[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_15 (Average)            (None, 10, 30)       0           text_output[0][0]                \n",
      "                                                                 node_embedding_transformation_3[0\n",
      "==================================================================================================\n",
      "Total params: 1,345,842\n",
      "Trainable params: 1,345,842\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 256  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "feed_forward_dim = 256  # Hidden layer size in feed forward network inside transformer\n",
    "node_embedding_dim = graph_embedding_size * 2\n",
    "\n",
    "def get_node_embedding_weights(model):\n",
    "    return model.get_layer('node_embedding_layer').get_weights()\n",
    "\n",
    "def set_node_embedding_weights(model, weights):\n",
    "    return model.get_layer('node_embedding_layer').set_weights(weights)\n",
    "\n",
    "def get_transformer_weights(model, transformer_name, output_name):\n",
    "    weights = []\n",
    "    weights.append(model.get_layer(transformer_name).get_weights())\n",
    "    weights.append(model.get_layer(output_name).get_weights())\n",
    "    return weights\n",
    "    \n",
    "def set_transformer_weights(model, transformer_name, output_name, weights):\n",
    "    model.get_layer(transformer_name).set_weights(weights[0])\n",
    "    model.get_layer(output_name).set_weights(weights[1])\n",
    "\n",
    "def cosine_similarity_loss(y_true, y_pred):\n",
    "    if print_output:\n",
    "        for y_p, y_t in zip(y_pred, y_true):\n",
    "            similarities_p_list, tokens_p_list, similarities_t_list, tokens_t_list = [], [], [], []\n",
    "            for i in range(maxlen):\n",
    "                similarities_p, tokens_p = generator.cosine_similarity(y_p[i])\n",
    "                similarities_t, tokens_t = generator.cosine_similarity(y_t[i])\n",
    "                similarities_p_list.append(similarities_p)\n",
    "                tokens_p_list.append(tokens_p)\n",
    "                similarities_t_list.append(similarities_t)\n",
    "                tokens_t_list.append(tokens_t)\n",
    "    \n",
    "            print('real: ', ' '.join([vocab[token] for token in tokens_t_list]))\n",
    "            print('prediction: ', ' '.join([vocab[token] for token in tokens_p_list]))\n",
    "            print('---------')\n",
    "            \n",
    "    # Normalize the vectors\n",
    "    y_true_normalized = tf.nn.l2_normalize(y_true, axis=-1)\n",
    "    y_pred_normalized = tf.nn.l2_normalize(y_pred, axis=-1)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarities = tf.reduce_sum(tf.multiply(y_true_normalized, y_pred_normalized), axis=-1)\n",
    "\n",
    "    # if print_output:\n",
    "    # tf.print(1 - cosine_similarities, summarize=-1)\n",
    "    \n",
    "    # Return 1 - cosine similarity as the loss\n",
    "    return 1 - cosine_similarities\n",
    "    \n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    if print_output:\n",
    "        for y_p, y_t in zip(y_pred, y_true):\n",
    "            distances_p_list, tokens_p_list, distances_t_list, tokens_t_list = [], [], [], []\n",
    "            for i in range(maxlen):\n",
    "                distances_p, tokens_p = generator.euclidean_distance(y_p[i])\n",
    "                distances_t, tokens_t = generator.euclidean_distance(y_t[i])\n",
    "                distances_p_list.append(distances_p)\n",
    "                tokens_p_list.append(tokens_p)\n",
    "                distances_t_list.append(distances_t)\n",
    "                tokens_t_list.append(tokens_t)\n",
    "    \n",
    "            print('real: ', ' '.join([vocab[token] for token in tokens_t_list]))\n",
    "            print('prediction: ', ' '.join([vocab[token] for token in tokens_p_list]))\n",
    "            print('---------')\n",
    "\n",
    "    # Calculate the squared differences between corresponding elements\n",
    "    squared_diff = tf.square(y_true - y_pred)\n",
    "    \n",
    "    # Sum the squared differences along the appropriate axis\n",
    "    loss = tf.reduce_sum(squared_diff, axis=-1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "def create_model():\n",
    "    inputs = layers.Input(shape=(maxlen,), dtype=\"float32\")\n",
    "    \n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim, name='embedding_layer')\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim, name='transformer_layer')\n",
    "    x = transformer_block(x)\n",
    "\n",
    "    outputs_1 = layers.Dense(vocab_size, name='text_output')(x)\n",
    "\n",
    "    node_embedding_layer = NodeEmbedding(embed_dim, final_embeddings, name='node_embedding_layer')\n",
    "    x2 = node_embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim, name='node_transformer_layer')\n",
    "    x2 = transformer_block(x2)\n",
    "    x2 = layers.Dense(node_embedding_dim, name='graph_embedding_output')(x2)\n",
    "    \n",
    "    outputs_2 = NodeEmbeddingTransformation(final_embeddings)(x2)\n",
    "\n",
    "    outputs = layers.Average()([outputs_1, outputs_2])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[outputs])\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=[loss_fn],\n",
    "        metrics=[]\n",
    "    )  # No loss and optimization based on word embeddings from transformer block\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "1cce73d0-6f9a-4586-bc1c-b9087b379b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(text_ds, verbose=0, epochs=500, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0ebde436-727e-4250-beb3-17f2fc256281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Results')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['mse', 'loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "98289dd9-d6cd-4fff-91ba-7c6fcfdcd90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[2.2954600e-04, 2.0358537e-04, 1.9376294e-04, 2.6391457e-05,\n",
       "        8.9572481e-05, 8.1020837e-05, 2.4915749e-04, 1.4953318e-04,\n",
       "        2.8746538e-03, 8.1836030e-02, 1.8642026e-05, 6.9020940e-03,\n",
       "        7.2501081e-01, 1.1725846e-05, 2.0107714e-02, 1.2624429e-03,\n",
       "        2.3110354e-06, 5.6573729e-13, 3.3458773e-06, 7.2720897e-04,\n",
       "        9.4953401e-05, 1.5950938e-01, 3.4415507e-16, 1.1396639e-13,\n",
       "        1.6336655e-04, 2.5236965e-04, 2.3011816e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([6.7272744, 6.736189, 6.739858, 6.886166, 6.796858, 6.8042355, 6.7211785,\n",
    "                               6.7590537, 6.5367146, 6.2753367, 6.9113607, 6.46937, 6.0990477, 6.9448204,\n",
    "                               6.3861933, 6.5993576, 7.060781, 8.06706, 7.0345287, 6.6410174, 6.792565,\n",
    "                               6.2219343, 8.513651, 8.165763, 6.7525053, 6.7202253, 7.222291])\n",
    "\n",
    "sm = keras.activations.softmax(tf.expand_dims(tf.negative(tf.square(t)),0))\n",
    "plt.plot(sm[0])\n",
    "plt.show()\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "1c4a5f37-eb02-402f-a397-98915cf43202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:\n",
      "what does a piano have ? organ organ organ organ organ organ organ organ organ organ organ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = callback('what does a piano have ?', model, 1)\n",
    "output = generator.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "38a17fcb-d0d3-4944-9852-5cfa23c1eafb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 keys 0.28698196911026097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.928563"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('graph_embedding_output').output)\n",
    "text = 'what does a piano have ?'\n",
    "generator = callback(text, model, 1)\n",
    "start_tokens, tokens_generated, num_tokens_generated, raw_output = generator.generate_token([_ for _ in generator.start_tokens], [])\n",
    "index = len(generator.start_tokens) - 1\n",
    "\n",
    "# for j in range(maxlen):\n",
    "dists = []\n",
    "for i, word in enumerate(vocab):\n",
    "    dist = euclidean_distance(raw_output[1][0][5],final_embeddings[i])\n",
    "    dists.append(dist)\n",
    "    # print(i, word, dist)\n",
    "sims = np.array(dists)\n",
    "print(np.argmin(dists), vocab[np.argmin(dists)], np.min(dists))\n",
    "\n",
    "sentence = []\n",
    "for token_index in tf.argmax(raw_output[0][0], -1):\n",
    "    sentence.append(vocab[token_index]) if token_index < len(vocab) else None\n",
    "\n",
    "' '.join(sentence)\n",
    "raw_output[0][0][5][25]\n",
    "# vocab[25]\n",
    "# vocab.index('keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94e2128-0c74-43ba-95aa-9f9aa037f202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0.87812877\n",
      "1 [UNK] 0.8876415\n",
      "2 what 0.42489213\n",
      "3 a 0.5319029\n",
      "4 ? 0.06366684\n",
      "5 have -0.08206626\n",
      "6 does -0.9477331\n",
      "7 . 0.53725916\n",
      "8 is -0.009818074\n",
      "9 violin 0.91280884\n",
      "10 piano 0.6942938\n",
      "11 instrument 0.9911488\n",
      "12 guitar 0.9265273\n",
      "13 truck 0.32573274\n",
      "14 trombone 0.8505727\n",
      "15 strings 0.9098007\n",
      "16 neck 0.8629197\n",
      "17 car 0.38960567\n",
      "18 wheels 0.4401339\n",
      "19 vehicle 0.39378682\n",
      "20 trunk 0.50748616\n",
      "21 slide 0.82245666\n",
      "22 pedals 0.6554069\n",
      "23 part 0.7562684\n",
      "24 keys 0.6387251\n",
      "25 bell 0.7870046\n",
      "26 baggage 0.5516417\n",
      "11 instrument 0.9911488\n"
     ]
    }
   ],
   "source": [
    "graph_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('graph_embedding_output').output)\n",
    "text = 'what does a guitar have ?'\n",
    "generator = callback(text, graph_model, 1)\n",
    "start_tokens, tokens_generated, num_tokens_generated, raw_output, similarities = generator.generate_token([_ for _ in generator.start_tokens], [])\n",
    "index = len(generator.start_tokens) - 1\n",
    "\n",
    "sims = []\n",
    "for i, word in enumerate(vocab):\n",
    "    sim = cosine_sim(raw_output[0][5],final_embeddings[i])\n",
    "    sims.append(sim)\n",
    "    print(i, word, sim)\n",
    "sims = np.array(sims)\n",
    "print(np.argmax(sims), vocab[np.argmax(sims)], np.max(sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4897c75c-bb0d-4ad4-a985-0747a9cd2581",
   "metadata": {},
   "source": [
    "### Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1e450afa-302a-4300-81a0-012bdc5bbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, input):\n",
    "    start_tokens = [word_to_index.get(_, 1) for _ in input.split()]\n",
    "    print(start_tokens)\n",
    "    pad_len = maxlen - len(start_tokens)\n",
    "    sample_index = len(start_tokens) - 1\n",
    "    if pad_len < 0:\n",
    "        x = start_tokens[:maxlen]\n",
    "        sample_index = maxlen - 1\n",
    "    elif pad_len > 0:\n",
    "        x = start_tokens + [0] * pad_len\n",
    "    else:\n",
    "        x = start_tokens\n",
    "    x = np.array([x])\n",
    "    print(sample_index)\n",
    "\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e46b262a-dfbb-40e1-8020-d2f95d7b2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 3, 12, 5, 4]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['does', 'a', 'guitar', 'have', '?', 'neck', '', '', '', '']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = generate_embeddings(model, 'what does a guitar have ?')\n",
    "tokens = []\n",
    "for output in final_output[0]:\n",
    "    tokens.append(vocab[tf.argmax(output)])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "411c0c5c-01cd-406b-89b9-cb275dededec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = keras.Model(inputs=[model.input], outputs=[model.get_layer('embedding_layer').output])\n",
    "transformer_model = keras.models.Sequential([\n",
    "    keras.layers.Input((10,128)),\n",
    "    TransformerBlock(embed_dim, num_heads, feed_forward_dim, name='transformer_layer'),\n",
    "    keras.layers.Dense(vocab_size, name='text_output')\n",
    "])\n",
    "original_weights = get_transformer_weights(model, 'transformer_layer', 'text_output')\n",
    "set_transformer_weights(transformer_model, 'transformer_layer', 'text_output', original_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7d02b0ee-c91c-4f9f-8d8c-25c97c894b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensor(\"strided_slice:0\", shape=(None, 10), dtype=int64)\n",
      "y Tensor(\"strided_slice_1:0\", shape=(None, 10), dtype=int64)\n",
      "[2, 6, 3, 12, 5, 4]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is', 'a', 'guitar', 'have', '?', 'neck', '', '', '', '']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['what does a guitar have ?']\n",
    "dataset = tf_data.Dataset.from_tensor_slices(texts)\n",
    "dataset = dataset.map(prepare_lm_inputs_labels)\n",
    "vectors = generate_embeddings(embedding_model, 'what does a guitar have ?')\n",
    "outputs = transformer_model.predict(vectors)\n",
    "tokens = []\n",
    "for output in outputs[0]:\n",
    "    tokens.append(vocab[tf.argmax(output)])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "bd6066c8-811e-47bd-80e6-a1adb0cd0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNodeEmbedding(layers.Layer):\n",
    "    def __init__(self, node_embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_embed_dim = node_embed_dim\n",
    "        self.dense = layers.Dense(node_embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        node_emb = self.dense(x)  # Apply dense layer to each token embedding\n",
    "        return node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "4895cfc9-be92-48b2-ba1c-2269585ab8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_node_embedding_model = keras.models.Sequential([\n",
    "    keras.layers.Input((graph_embedding_size)),\n",
    "    CustomNodeEmbedding(embed_dim)\n",
    "]\n",
    ")\n",
    "\n",
    "custom_node_embedding_model.layers[0].set_weights(model.get_layer('node_embedding_layer').get_weights())\n",
    "\n",
    "\n",
    "node_embedding_model = keras.Model(inputs=[model.input], outputs=[model.get_layer('node_embedding_layer').output])\n",
    "# set_node_embedding_weights(node_embedding_model, get_node_embedding_weights(model))\n",
    "node_transformer_model = keras.models.Sequential([\n",
    "    keras.layers.Input((10,128)),\n",
    "    TransformerBlock(embed_dim, num_heads, feed_forward_dim, name='node_transformer_layer'),\n",
    "    keras.layers.Dense(vocab_size, name='graph_output')\n",
    "])\n",
    "original_weights = get_transformer_weights(model, 'node_transformer_layer', 'graph_output')\n",
    "set_transformer_weights(node_transformer_model, 'node_transformer_layer', 'graph_output', original_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "11e6dc57-14dd-416c-a6de-ac2a250dac43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9145890235900879"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [final_embeddings[vocab.index(word)] for word in 'what does a guitar have ?'.split(' ')]\n",
    "for i in range(maxlen - len(embeddings)):\n",
    "    embeddings.append(final_embeddings[0])\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "# embeddings[3][0] += 0.1\n",
    "embeddings[3] = final_embeddings[vocab.index('piano']\n",
    "embeddings[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "9490897a-2aa3-4745-9698-7668bd775a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x Tensor(\"strided_slice:0\", shape=(None, 10), dtype=int64)\n",
      "y Tensor(\"strided_slice_1:0\", shape=(None, 10), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is', 'a', 'truck', '.', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['what does a piano have ? neck.']\n",
    "dataset = tf_data.Dataset.from_tensor_slices(texts)\n",
    "dataset = dataset.map(prepare_lm_inputs_labels)\n",
    "# vectors = generate_embeddings(node_embedding_model, 'what does a guitar have ?')\n",
    "vectors = custom_node_embedding_model.predict(embeddings)\n",
    "vectors = np.expand_dims(vectors, axis=0)\n",
    "outputs = node_transformer_model.predict(vectors)\n",
    "tokens = []\n",
    "for output in outputs[0]:\n",
    "    tokens.append(vocab[tf.argmax(output)])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "59f4c460-8fc4-41df-a3dc-8334a61d1626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.288712\n",
      "[UNK] 0.97452706\n",
      "what -1.2253331\n",
      "a -0.7780448\n",
      "? 2.1183078\n",
      "have -0.8638337\n",
      "does -1.9659276\n",
      ". -0.2755831\n",
      "is -1.4778473\n",
      "violin -1.8833617\n",
      "piano -2.9525533\n",
      "instrument 6.613864\n",
      "guitar -1.6347598\n",
      "truck 0.025299525\n",
      "strings 5.4872427\n",
      "neck 4.991041\n",
      "car -1.252157\n",
      "wheels -2.1652482\n",
      "vehicle -0.6221498\n",
      "trunk -1.6674696\n",
      "pedals -1.3050263\n",
      "part -1.7248017\n",
      "keys -0.9800917\n",
      "baggage -1.3884528\n"
     ]
    }
   ],
   "source": [
    "for token, val in zip(vocab, outputs[0][5]):\n",
    "    print(token,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e844789a-13df-4243-875c-9a6e6901da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9307133"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][4][vocab.index('what')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b8639bf1-215d-44c9-97ce-92eff7c04554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.07046904,  0.06283123, -0.02485108,  0.09587689,  0.142355  ,\n",
       "        -0.06232064, -0.00856199]),\n",
       " array([-0.01341391,  0.1197396 ,  0.12872545,  0.09337865, -0.01016603,\n",
       "         0.11014863, -0.12191909]),\n",
       " array([-0.08136626,  0.05501175,  0.03980896,  0.09844395,  0.08715851,\n",
       "         0.13626422,  0.13247739]),\n",
       " array([ 0.84344125, -0.02662537, -1.49284065,  0.77122533, -1.93575537,\n",
       "        -1.42882872,  2.14216161]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings[vocab.index('what')],final_embeddings[vocab.index('does')], final_embeddings[vocab.index('a')], final_embeddings[vocab.index('piano')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b4b1c-c345-43c2-8ca6-e90b9b951ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc20091-ad10-4e12-9e93-bf6fb7b58f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-37",
   "language": "python",
   "name": "tf-37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

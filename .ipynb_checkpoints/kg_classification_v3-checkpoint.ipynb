{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from graph_visualization import GraphVisualization\n",
    "\n",
    "from neomodel import config, db\n",
    "\n",
    "config.DATABASE_URL = 'neo4j://neo4j:cuneyt123@localhost:7687'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_of_clusters(data):\n",
    "    clusters = []\n",
    "    for i,d in enumerate(data):\n",
    "        print('%.2f%%' % ((i * 100) / len(data))) if i % 10 == 0 else None\n",
    "        nodes = []\n",
    "        for dd in d['data']:\n",
    "            for node in dd['instance_of']:\n",
    "                nodes.append(node)      \n",
    "        \n",
    "        clusters.append({'nodes': nodes})\n",
    "        \n",
    "    with open('data/instance_of_clusters.pkl', 'wb') as outp:\n",
    "        pickle.dump(clusters, outp, pickle.HIGHEST_PROTOCOL)\n",
    "                                       \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_of(dbpedia_uri):\n",
    "    query = \"\"\"\n",
    "MATCH(e:Entity{dbpedia_uri: $dbpedia_uri})-[rel:INSTANCE_OF]->(e2:Entity)\n",
    "return  distinct e.name,type(rel),e2.name\n",
    "\"\"\"\n",
    "\n",
    "    results, meta = db.cypher_query(query, {'dbpedia_uri': dbpedia_uri})\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_instance_of_obj(data):\n",
    "    for i1, data_ in enumerate(data):\n",
    "        print(f\"Getting graphs for {data_['label']}\")\n",
    "        for i2, d in enumerate(data_['data']):\n",
    "            print(\"%.2f TOTAL - %.2f CATEGORY\" % ((i1 * len(data_['data']) + i2) / (len(data) * len(data_['data'])), i2 / len(data_['data'])))\n",
    "\n",
    "            results = get_instance_of(d['dbpedia_uri'])\n",
    "\n",
    "            instance_of = []\n",
    "            for row in results:\n",
    "                instance_of.append(row[2]) if row[2] and row[2] not in instance_of else None\n",
    "\n",
    "            d['instance_of'] = instance_of\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data/topic_texts_data_markup_100_v3.pkl', 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_instance_of_obj(data)\n",
    "\n",
    "instance_of_clusters = get_instance_of_clusters(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

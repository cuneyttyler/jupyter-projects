{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d24ba4-1c38-4c57-a7d5-1cfc6f288df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import tempfile\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Embedding, Activation, Softmax\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv1D,Conv2D, ZeroPadding2D, MaxPooling1D, MaxPooling2D\n",
    "from keras.layers import RepeatVector, Permute, Add, Concatenate, Reshape, Dot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph, IndexedArray\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "BASE_DIR = '.'\n",
    "GLOVE_DIR = '/media/drived/Dev/Glove'\n",
    "# TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
    "DATA_DIR = \"/home/bhargav/nlu_project/keras_n20/data/Es_Rc\"\n",
    "DOC_PKL = \"document_list.pick\"\n",
    "TARGET_PKL = \"target_list.pick\"\n",
    "\n",
    "OUTPUT_PATH = './learning_beyond_datasets/node2vec/lstm_and_kg/'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "MAX_NUM_WORDS = 20000\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "NUM_RELATIONS_PER_CLUSTER = 67\n",
    "NUM_ENTITIES_PER_CLUSTER = 400\n",
    "NUM_CLUSTERS = 20\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "def get_clusters(cluster_file, num_things_per_cluster):\n",
    "    clusters = []  # np.ones(shape=(NUM_RELATIONS_PER_CLUSTER,KG_EMBEDDING_DIM))\n",
    "\n",
    "    with open(cluster_file, 'r', encoding='utf8') as f:\n",
    "        lines = []\n",
    "        for line in f:\n",
    "            elements = line.split()\n",
    "            x = [[e] for e in elements]\n",
    "            lines.append(x)\n",
    "\n",
    "    for i in range(0, len(lines) - num_things_per_cluster + 1, num_things_per_cluster):\n",
    "        # print(\"appending: {} to {}\".format(i,i+num_things_per_cluster))\n",
    "        clusters.append(lines[i:i + num_things_per_cluster])\n",
    "\n",
    "    clusters = np.asarray(clusters, dtype='float32')\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def pickler(path, pkl_name, obj):\n",
    "    with open(os.path.join(path, pkl_name), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def unpickler(path, pkl_name):\n",
    "    with open(os.path.join(path, pkl_name), 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def get_labels(data):\n",
    "    labels = []\n",
    "    for d in data:\n",
    "        labels.append(d['label']) if d['label'] not in labels else None\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_x_and_y(data):\n",
    "    x, y = [], []\n",
    "    for d in data:\n",
    "        for dd in d['data']:\n",
    "            tmp = dd['text'].replace('\\n', '').replace('_', '')  # clean\n",
    "            x.append({'label': d['label'], 'dbpedia_uri': dd['dbpedia_uri'], 'context_data': dd['context_data'], 'text': tmp, 'graph': dd['graph']}) if len(tmp) > 0 else None\n",
    "            y.append(d['label']) if len(tmp) > 0 else None\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_label_index(label):\n",
    "    return [index for index, _label in enumerate(unique_labels) if label == _label][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde0e98-5af0-4d57-9189-837ea9dfdad6",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2ca003-e61b-498a-83ac-861c234693e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_clusters(arr):    \n",
    "    result = []\n",
    "    for el in arr:\n",
    "        all_mappings = node_cluster_mapping_v3_with_count[el] if el in node_cluster_mapping_v3_with_count else []\n",
    "        filtered_mappings = [e[0] for e in all_mappings[:min(len(all_mappings),3)]]\n",
    "        result.extend(filtered_mappings)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_context_data(data):\n",
    "    for d in data:\n",
    "        for dd in d['data']:\n",
    "            dd['context_data'] = [c for c in set(find_clusters(dd['context_graph']['nodes']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9cce4d-cbb3-4edb-80a0-7e1339f44667",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "with open(r'data/classification_data_with_graphs_v4.pkl', 'rb') as pickle_file:\n",
    "    data = pickle.load(pickle_file)\n",
    "\n",
    "unique_labels = get_labels(data)\n",
    "\n",
    "node_cluster_mapping_v3_with_count = unpickler('data','node_cluster_mapping_v3_with_count.pkl')\n",
    "get_context_data(data)\n",
    "\n",
    "x, labels = get_x_and_y(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc89d37-d751-414a-aa94-a420cf4f5633",
   "metadata": {},
   "source": [
    "### GET NODE EMBEDDINGS/GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def2b61e-25d4-4cbc-882b-11586788df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'data/node_embeddings_v3.pkl', 'rb') as pickle_file:\n",
    "    node_embeddings = pickle.load(pickle_file)\n",
    "with open(r'data/graph.pkl', 'rb') as pickle_file:\n",
    "    graph = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14094c-b731-4ba4-8a2d-6fb50418849c",
   "metadata": {},
   "source": [
    "### GET GRAPH CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982cf138-2bb9-4cc1-b876-c6b44336878f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters_v1 = unpickler('data','node_clusters.pkl')\n",
    "clusters_v2 = unpickler('data','node_clusters_v2.pkl')\n",
    "clusters_v3 = unpickler('data','node_clusters_v3.pkl')\n",
    "# clusters_v3 = get_graph_clusters()\n",
    "# cluster_embeddings = get_embeddings(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0435d5f-c115-4b82-b47b-edc4877c0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_v3_filtered = unpickler('data','node_clusters_v3_filtered.pkl')\n",
    "clusters_v3_filtered = unpickler('data','node_clusters_v3_with_count.pkl')\n",
    "node_cluster_mapping_v2 = unpickler('data','node_cluster_mapping_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd9f3b-92cf-49e0-849c-7c33ac5864f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PARSE INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc999b5-90a5-4f57-aa02-2b4e30dc6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_data = []\n",
    "\n",
    "x_train, x_test, labels_train, labels_test = train_test_split(x, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "y_train, y_test = [get_label_index(label) for label in labels_train],[get_label_index(label) for label in labels_test]\n",
    "\n",
    "x_val, y_val,x_test, y_test = x_test[:500], y_test[:500], x_test[500:], y_test[500:]\n",
    "\n",
    "x_train_text,x_test_text = [xx['text'] for xx in x_train], [xx['text'] for xx in x_test]\n",
    "\n",
    "# print('x_train:{} y_train:{} x_val:{} y_val:{} '.format(x_train.shape, y_train.shape, x_val.shape, y_val.shape))\n",
    "\n",
    "x_train_text,x_val_text,x_test_text = [xx['text'] for xx in x_train],[xx['text'] for xx in x_val], [xx['text'] for xx in x_test]\n",
    "x_train_context, x_val_context, x_test_context = [xx['context_data'] for xx in x_train],[xx['context_data'] for xx in x_val], [xx['context_data'] for xx in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7ab9c9-df5e-4758-bc8c-8b4d03da09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{{}}A cruiseferry is a ship that combines the features of a cruise ship and a Ro-Pax ferry. Many passengers travel with the ships for the cruise experience, staying only a few hours at the destination port or not leaving the ship at all, while others use the ships as means of transportation.Cruiseferry traffic is mainly concentrated in the seas of Northern Europe, especially the Baltic Sea and the North Sea. However, similar ships traffic across the English Channel as well as the Irish Sea, Mediterranean and even on the North Atlantic. Cruiseferries also operate from India, China and Australia.Baltic Sea cruiseferriesIn the northern Baltic Sea, two major rival companies, Viking Line and Silja Line, have for decades competed on the routes between Turku and Helsinki in Finland and Sweden\\'s capital Stockholm. Since the 1990s Tallink has also risen as a major company in the area, culminating with acquisition of Silja Line in 2006.List of largest cruiseferries of their timeThe term \"cruiseferry\" did not come into use until the 1980s, although it has been retroactively applied to earlier ferries that have large cabin capabilities and public spaces in addition to their car- and passenger-carrying capacity.{|class=\"wikitable\"!Year !Name!Tonnage<sup>1</sup>!Company!Traffic area!Flag!Notes|-|| MS Belorussiya|align=\"Center\" |Alongside five identical sisters build 1975–76|-|| | Send to Comarit in 2002.|-|| GTS Finnjet|align=\"Center\" | Gas turbine-powered. Also fastest and longest|-|| MS Finlandia|align=\"Center\" | Alongside identical sister MS Silvia Regina|-|| MS Scandinavia|align=\"Center\" ||-|| MS Svea|align=\"Center\" ||-|| MS Mariella|align=\"Center\" ||-|| MS Athena|align=\"Center\" ||-|| MS Cinderella|align=\"Center\" ||-|| MS Silja Serenade|align=\"Center\" ||-|| MS Silja Symphony|align=\"Center\" ||-|| MS Silja Europa|align=\"Center\" | Ordered by Rederi AB Slite for Viking Line traffic|-|| MS Pride of Rotterdam|align=\"Center\" ||-|| MS Pride of Hull|align=\"Center\" ||-|| MS Color Fantasy|align=\"Center\" ||-|| MS Color Magic|align=\"Center\" ||-| colspan=\"7\" <sup>1</sup>May be specified in gross tonnage (GT) or gross register tons (GRT).|}List of cruiseferry operatorsÅland* Eckerö Linjen*) Viking LineAustralia* Spirit of TasmaniaCanada* BC Ferries* Marine AtlanticCroatia* JadrolinijaDenmark* DFDS SeawaysEstonia* TallinkFaroe Islands* Smyril LineFinland* Eckerö Line* Tallink)*) Viking Line* Finnlines* Wasa LineFrance* Brittany Ferries* Corsica Ferries - Sardinia Ferries* Corsica LineaGreece* ANEK Lines* Blue Star Ferries* Hellenic Seaways* LANE Lines* Levante Ferries* Minoan Lines* NEL Lines* Superfast Ferries* Ventouris FerriesIreland* Irish Ferries* P&O Ferries* Stena LineItaly* Grandi Navi Veloci* Grimaldi Lines* Corsica Ferries* Moby Lines* Tirrenia di NavigazioneMexico* Baja FerriesNorway* Color Line* Fjord LinePoland*PolferriesSpain* Trasmediterranea* BaleàriaSweden* Stena LineUnited Kingdom* P&O Ferries* NorthLink Ferries* Condor Ferries* Irish Ferries* Stena LineGallery<gallery>Image:PontAven0419., Brittany Ferries\\' flagship.Image:Silja Europa 2005.M/M/S Silja Europa, the largest cruiseferry in the world 1993–2001.Image:Cinderella-vintern-2003.M/M/S Cinderella departing Helsinki.Image:Bateau Mega Regina Entrant Port - L\\'Île-Rousse (FR2B) - 2021-09-05 - 6 (cropped).M/S Mega Regina at Ile Rousse Image:Color Fantasy Heck.M/M/S Color Fantasy, the largest cruiseferry in the world 2004–2007.Image:Cruise Roma Civitavecchia.MS Cruise Roma in Civitavecchia, Italy.Image:Casa BIA.M/S Danielle Casanova in Bastia, Corsica, France.Image:PrideofRotterdam.M/S Pride of RotterdamImage:TallinkGalaxy.MS Galaxy in Helsinki West Harbour.Image:Brosengdanskpolferriesscandinavia2.MS Scandinavia in Gdańsk, Poland.Image:Pearl of Scandinavia.M/S Pearl of Scandinavia in Oslo, NorwayFile:CapFinistère.MV Cap Finistère of Brittany Ferries sailing from Portsmouth International Port, UK for Bilbao, Spain.</gallery>See also* River cruise',\n",
       " 76,\n",
       " 'Transportation-Naval',\n",
       " 'Transportation-Naval')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 55\n",
    "x_train_text[i], y_train[i], labels_train[i], unique_labels[y_train[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d456275-3193-46d0-881b-e8ef38539a4a",
   "metadata": {},
   "source": [
    "### PREPARE NEURAL NET MODEL SIMPLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24239f9b-8d10-4a6b-a42b-46b45482952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH CLUSTER      NODE_CLUSTER_MAPPING           GRAPH INPUT\n",
    "0 Philosophy       Schopenhaur, Kant              Kant, Socrates\n",
    "1 Music            Led Zeppelin, Pearl Jam\n",
    "\n",
    "For each element in graph input, find the corresponding cluster, attend over it\n",
    "\n",
    "1. Finding graph input node clusters:\n",
    "    We know cluster indexes.\n",
    "    Write a lambda function to convert graph inputs to clusters then encode them(one-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e9141e-750a-4b0b-b073-7e7588cdd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 200\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "vectorize_layer.adapt(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e665141-a4ac-4f01-b072-937bc20e3750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 100)          50100     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 78)                7878      \n",
      "=================================================================\n",
      "Total params: 57,978\n",
      "Trainable params: 57,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_HIDDEN_SIZE = 200\n",
    "LEARNING_RATE = 0.001\n",
    "KG_EMBEDDING_DIM = 100\n",
    "MAX_TOKENS_NUM = 500\n",
    "EMBEDDING_DIMS = 100\n",
    "\n",
    "Transpose = keras.layers.core.Lambda(lambda x: K.transpose(x))\n",
    "\n",
    "cluster_names = unique_labels + ['None']\n",
    "                             \n",
    "text_input = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
    "\n",
    "text_layer = vectorize_layer(text_input)\n",
    "text_layer = tf.keras.layers.Embedding(MAX_TOKENS_NUM + 1, EMBEDDING_DIMS)(text_layer)\n",
    "text_layer = tf.keras.layers.GlobalAveragePooling1D()(text_layer)\n",
    "\n",
    "# context_input = Input(shape=(1,), dtype='string', name='graph_input')                           \n",
    "# context_layer = tf.keras.layers.StringLookup(vocabulary=cluster_names, output_mode='multi_hot')(context_input)\n",
    "\n",
    "# concatenated = Concatenate(axis=1)([text_layer, context_layer])\n",
    "# final_output = Dense(units=len(unique_labels), activation='softmax')(concatenated)\n",
    "final_output = Dense(units=len(unique_labels))(text_layer)\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE, clipvalue=0.25)\n",
    "\n",
    "m = Model(inputs=[text_input], outputs=final_output)\n",
    "\n",
    "m.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=tf.metrics.SparseCategoricalAccuracy())\n",
    "\n",
    "m.summary()\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# plot_model(m, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a85f9-de8d-4e87-ba06-4a269440d537",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PREDICT SIMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f1fba2f-e208-4904-b3fc-0fef34459ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{{}}A cruiseferry is a ship that combines the features of a cruise ship and a Ro-Pax ferry. Many passengers travel with the ships for the cruise experience, staying only a few hours at the destination port or not leaving the ship at all, while others use the ships as means of transportation.Cruiseferry traffic is mainly concentrated in the seas of Northern Europe, especially the Baltic Sea and the North Sea. However, similar ships traffic across the English Channel as well as the Irish Sea, Mediterranean and even on the North Atlantic. Cruiseferries also operate from India, China and Australia.Baltic Sea cruiseferriesIn the northern Baltic Sea, two major rival companies, Viking Line and Silja Line, have for decades competed on the routes between Turku and Helsinki in Finland and Sweden\\'s capital Stockholm. Since the 1990s Tallink has also risen as a major company in the area, culminating with acquisition of Silja Line in 2006.List of largest cruiseferries of their timeThe term \"cruiseferry\" did not come into use until the 1980s, although it has been retroactively applied to earlier ferries that have large cabin capabilities and public spaces in addition to their car- and passenger-carrying capacity.{|class=\"wikitable\"!Year !Name!Tonnage<sup>1</sup>!Company!Traffic area!Flag!Notes|-|| MS Belorussiya|align=\"Center\" |Alongside five identical sisters build 1975–76|-|| | Send to Comarit in 2002.|-|| GTS Finnjet|align=\"Center\" | Gas turbine-powered. Also fastest and longest|-|| MS Finlandia|align=\"Center\" | Alongside identical sister MS Silvia Regina|-|| MS Scandinavia|align=\"Center\" ||-|| MS Svea|align=\"Center\" ||-|| MS Mariella|align=\"Center\" ||-|| MS Athena|align=\"Center\" ||-|| MS Cinderella|align=\"Center\" ||-|| MS Silja Serenade|align=\"Center\" ||-|| MS Silja Symphony|align=\"Center\" ||-|| MS Silja Europa|align=\"Center\" | Ordered by Rederi AB Slite for Viking Line traffic|-|| MS Pride of Rotterdam|align=\"Center\" ||-|| MS Pride of Hull|align=\"Center\" ||-|| MS Color Fantasy|align=\"Center\" ||-|| MS Color Magic|align=\"Center\" ||-| colspan=\"7\" <sup>1</sup>May be specified in gross tonnage (GT) or gross register tons (GRT).|}List of cruiseferry operatorsÅland* Eckerö Linjen*) Viking LineAustralia* Spirit of TasmaniaCanada* BC Ferries* Marine AtlanticCroatia* JadrolinijaDenmark* DFDS SeawaysEstonia* TallinkFaroe Islands* Smyril LineFinland* Eckerö Line* Tallink)*) Viking Line* Finnlines* Wasa LineFrance* Brittany Ferries* Corsica Ferries - Sardinia Ferries* Corsica LineaGreece* ANEK Lines* Blue Star Ferries* Hellenic Seaways* LANE Lines* Levante Ferries* Minoan Lines* NEL Lines* Superfast Ferries* Ventouris FerriesIreland* Irish Ferries* P&O Ferries* Stena LineItaly* Grandi Navi Veloci* Grimaldi Lines* Corsica Ferries* Moby Lines* Tirrenia di NavigazioneMexico* Baja FerriesNorway* Color Line* Fjord LinePoland*PolferriesSpain* Trasmediterranea* BaleàriaSweden* Stena LineUnited Kingdom* P&O Ferries* NorthLink Ferries* Condor Ferries* Irish Ferries* Stena LineGallery<gallery>Image:PontAven0419., Brittany Ferries\\' flagship.Image:Silja Europa 2005.M/M/S Silja Europa, the largest cruiseferry in the world 1993–2001.Image:Cinderella-vintern-2003.M/M/S Cinderella departing Helsinki.Image:Bateau Mega Regina Entrant Port - L\\'Île-Rousse (FR2B) - 2021-09-05 - 6 (cropped).M/S Mega Regina at Ile Rousse Image:Color Fantasy Heck.M/M/S Color Fantasy, the largest cruiseferry in the world 2004–2007.Image:Cruise Roma Civitavecchia.MS Cruise Roma in Civitavecchia, Italy.Image:Casa BIA.M/S Danielle Casanova in Bastia, Corsica, France.Image:PrideofRotterdam.M/S Pride of RotterdamImage:TallinkGalaxy.MS Galaxy in Helsinki West Harbour.Image:Brosengdanskpolferriesscandinavia2.MS Scandinavia in Gdańsk, Poland.Image:Pearl of Scandinavia.M/S Pearl of Scandinavia in Oslo, NorwayFile:CapFinistère.MV Cap Finistère of Brittany Ferries sailing from Portsmouth International Port, UK for Bilbao, Spain.</gallery>See also* River cruise',\n",
       " 'Transportation-Naval')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 55\n",
    "x_train_text[i], unique_labels[y_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe056c83-ce9d-44c7-87d3-2645b9f9323e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2250/2250 [==============================] - 8s 3ms/step - loss: 4.5909 - sparse_categorical_accuracy: 0.0156\n",
      "Epoch 2/10\n",
      "1384/2250 [=================>............] - ETA: 2s - loss: 4.3614 - sparse_categorical_accuracy: 0.0155"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3b3c29a412c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m history = m.fit(x_train_text, y_train,\n\u001b[1;32m     17\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# validation_data=(x_val_text, y_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                )\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "x_train_input = pd.DataFrame(x_train_text).values\n",
    "context_data_train_input = pd.DataFrame(x_train_context).values\n",
    "y_train_output = pd.DataFrame(y_train).values\n",
    "\n",
    "for c in context_data_train_input:\n",
    "    for i,v in enumerate(c):\n",
    "        c[i] = 'None' if not v else v \n",
    "\n",
    "# x_train_input = np.asarray(['Test' for i in range(len(x_train))])\n",
    "# context_data_train_input = np.asarray(['Art-Painting' for i in range(len(x_train_input))])\n",
    "# y_train_output = np.asarray([0 for i in range(len(x_train_input))])\n",
    "\n",
    "history = m.fit(x_train_text, y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                # validation_data=(x_val_text, y_val)\n",
    "               )\n",
    "# m.save('node2vec_lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610b543-455b-434e-81b3-202b953f5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7dc995a4-3c5f-40f6-8066-3f721bf4d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 6s 11ms/step - loss: 13.5225 - acc: 0.0000e+00\n",
      "Test loss / test accuracy = 13.5225 / 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Restore the best found model during validation\n",
    "# m.load_weights(tmpfn)\n",
    "\n",
    "x_test_input = pd.DataFrame(x_test_text).values\n",
    "context_data_test_input = pd.DataFrame(context_data_test).values\n",
    "y_test_output = pd.DataFrame(y_test).values\n",
    "\n",
    "for c in context_data_test_input:\n",
    "    for i,v in enumerate(c):\n",
    "        c[i] = 'None' if not v else v \n",
    "        \n",
    "loss, acc = m.evaluate([x_test_input], y_test_output, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b967276a-f801-4798-a29c-d6e093ec5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m.predict([x_test_input], batch_size=BATCH_SIZE, verbose=0,\n",
    "                  steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "287fc336-cbff-495c-8d08-cde5ed962ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Art-Painting'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ae998ec-eb5b-482c-9f10-49b932fc4302",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.00\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                Architecture       0.00      0.00      0.00      74.0\n",
      "      Architecture-Structure       0.00      0.00      0.00      98.0\n",
      "                  Art-Cinema       0.00      0.00      0.00       0.0\n",
      "            Art-Cinema-Actor       0.00      0.00      0.00       0.0\n",
      "                   Art-Dance       0.00      0.00      0.00       0.0\n",
      "            Art-Dance-Dancer       0.00      0.00      0.00       0.0\n",
      "                 Art-Fashion       0.00      0.00      0.00       0.0\n",
      "        Art-Fashion-Designer       0.00      0.00      0.00       0.0\n",
      "              Art-Literature       0.00      0.00      0.00       0.0\n",
      "       Art-Literature-Writer       0.00      0.00      0.00       0.0\n",
      "                   Art-Music       0.00      0.00      0.00       0.0\n",
      "        Art-Music-Instrument       0.00      0.00      0.00       0.0\n",
      "                Art-Painting       0.00      0.00      0.00       0.0\n",
      "         Art-Painting-Artist       0.00      0.00      0.00       0.0\n",
      "Art-Photography-Photographer       0.00      0.00      0.00       0.0\n",
      "               Art-Sculpting       0.00      0.00      0.00       0.0\n",
      "        Art-Sculpting-Artist       0.00      0.00      0.00       0.0\n",
      "                 Art-Theatre       0.00      0.00      0.00       0.0\n",
      "           Art-Theatre-Actor       0.00      0.00      0.00       0.0\n",
      "                   Astronomy       0.00      0.00      0.00       0.0\n",
      "           Astronomy-Program       0.00      0.00      0.00       0.0\n",
      "                     Culture       0.00      0.00      0.00       0.0\n",
      "             Culture-Country       0.00      0.00      0.00       0.0\n",
      "   Culture-Historical Figure       0.00      0.00      0.00       0.0\n",
      "                       Media       0.00      0.00      0.00      94.0\n",
      "                 Media-Anime       0.00      0.00      0.00     100.0\n",
      "               Media-Cartoon       0.00      0.00      0.00      96.0\n",
      "           Media-Documentary       0.00      0.00      0.00      98.0\n",
      "                  Media-News       0.00      0.00      0.00      97.0\n",
      "     Media-TV Series & Shows       0.00      0.00      0.00     100.0\n",
      "                    Military       0.00      0.00      0.00      85.0\n",
      "           Military-Aviation       0.00      0.00      0.00     100.0\n",
      "              Military-Naval       0.00      0.00      0.00      70.0\n",
      "             Military-Weapon       0.00      0.00      0.00      98.0\n",
      "                   Mythology       0.00      0.00      0.00       0.0\n",
      "      Mythology-Supernatural       0.00      0.00      0.00       0.0\n",
      "               Nature-Animal       0.00      0.00      0.00       0.0\n",
      "                 Nature-Food       0.00      0.00      0.00       0.0\n",
      "        Nature-Microorganism       0.00      0.00      0.00       0.0\n",
      "                Nature-Plant       0.00      0.00      0.00       0.0\n",
      "                  Philosophy       0.00      0.00      0.00       0.0\n",
      "                    Religion       0.00      0.00      0.00       0.0\n",
      "         Science-Agriculture       0.00      0.00      0.00       0.0\n",
      "         Science-Antropology       0.00      0.00      0.00       0.0\n",
      "          Science-Archeology       0.00      0.00      0.00       0.0\n",
      "             Science-Biology       0.00      0.00      0.00       0.0\n",
      "           Science-Chemistry       0.00      0.00      0.00       0.0\n",
      "      Science-Earth Sciences       0.00      0.00      0.00       0.0\n",
      "           Science-Economics       0.00      0.00      0.00       0.0\n",
      "         Science-Mathematics       0.00      0.00      0.00       0.0\n",
      "            Science-Medicine       0.00      0.00      0.00       0.0\n",
      "         Science-Meteorology       0.00      0.00      0.00       0.0\n",
      "       Science-Paleonthology       0.00      0.00      0.00       0.0\n",
      "             Science-Physics       0.00      0.00      0.00       0.0\n",
      "            Science-Politics       0.00      0.00      0.00       0.0\n",
      "          Science-Psychology       0.00      0.00      0.00       0.0\n",
      "     Science-Social Sciences       0.00      0.00      0.00       0.0\n",
      "                      Sports       0.00      0.00      0.00      99.0\n",
      "Technology-Civil Engineering       0.00      0.00      0.00       0.0\n",
      " Technology-Computer Science       0.00      0.00      0.00       0.0\n",
      "      Technology-Electronics       0.00      0.00      0.00       0.0\n",
      "        Technology-Mechanics       0.00      0.00      0.00       0.0\n",
      "         Technology-Robotics       0.00      0.00      0.00       0.0\n",
      "       Technology-Video Game       0.00      0.00      0.00       0.0\n",
      "\n",
      "                    accuracy                           0.00    1209.0\n",
      "                   macro avg       0.00      0.00      0.00    1209.0\n",
      "                weighted avg       0.00      0.00      0.00    1209.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def get_result_labels(results):\n",
    "    return [unique_labels[np.where(row==max(row))[0][0]] for row in results]\n",
    "\n",
    "result_labels = get_result_labels(preds)\n",
    "\n",
    "print('Accuracy score: %.2f' % accuracy_score(result_labels, y_test_str))\n",
    "print(classification_report(y_test_str, result_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684383ab-27f8-4eb7-bf97-f0427fc48d50",
   "metadata": {},
   "source": [
    "### PREPARE NEURAL NET MODEL WITH EMBEDDINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d31ce-61fc-444d-9bee-d55a8a6a0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH CLUSTER      NODE_CLUSTER_MAPPING           GRAPH INPUT\n",
    "0 Philosophy       Schopenhaur, Kant              Kant, Socrates\n",
    "1 Music            Led Zeppelin, Pearl Jam\n",
    "\n",
    "For each element in graph input, find the corresponding cluster, attend over it\n",
    "\n",
    "1. Finding graph input node clusters:\n",
    "    We know cluster indexes.\n",
    "    Write a lambda function to convert graph inputs to clusters then encode them(one-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6081ad35-0773-4cec-b2e9-9c1065e0ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model.\n",
      "Shape (89539, 100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer max_pooling1d is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (89539, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-319153d1e610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# x = e_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# x = Conv1D(filters=1, kernel_size=5, strides=1, input_shape=node_embeddings.shape)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;31m# x = Conv1D(filters=1, kernel_size=5, strides=1)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# x = MaxPooling1D(pool_size=5, strides=1)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2634\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    216\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer max_pooling1d is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (89539, 100)"
     ]
    }
   ],
   "source": [
    "LSTM_HIDDEN_SIZE = 200\n",
    "LEARNING_RATE = 0.001\n",
    "KG_EMBEDDING_DIM = 300\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Preparing model.')\n",
    "\n",
    "# entity_clusters = K.variable(embedding_clusters_2d)\n",
    "\n",
    "Avg = keras.layers.core.Lambda(lambda x: K.mean(x, axis=1))  # , output_shape=(KG_EMBEDDING_DIM, ))\n",
    "DotProduct = keras.layers.core.Lambda(lambda x: K.dot(x[0], x[1]))  # , output_shape=(KG_EMBEDDING_DIM, ))\n",
    "Sum = keras.layers.core.Lambda(lambda x: K.sum(x, axis=1))  # , output_shape=(KG_EMBEDDING_DIM, ))\n",
    "RemoveLastCol = keras.layers.core.Lambda(lambda x: K.sum(x, axis=-1))\n",
    "Transpose = keras.layers.core.Lambda(lambda x: K.transpose(x))\n",
    "FakeEClusterIn = keras.layers.core.Lambda(lambda x: node_embedding_clusters)\n",
    "FindCluster = keras.layers.core.Lambda(lambda x: tf.map_fn(lambda el: node_cluster_mapping[el] if el in node_cluster_mapping else 0, x, dtype='string')\n",
    "\n",
    "cluster_names = unique_labels + ['None']\n",
    "                                       \n",
    "main_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='main_input')\n",
    "\n",
    "x = embedding_layer(main_input)\n",
    "x = CuDNNLSTM(LSTM_HIDDEN_SIZE, return_sequences=True)(x)\n",
    "Avg = keras.layers.core.Lambda(lambda x: K.mean(x, axis=1), output_shape=(LSTM_HIDDEN_SIZE,))\n",
    "x = Avg(x)\n",
    "x = Dense(LSTM_HIDDEN_SIZE)(x)\n",
    "main_lstm_out = Activation('relu')(x)\n",
    "\n",
    "# get representation for entity clusters\n",
    "e_clusters = Input(name='e_clusters')\n",
    "# x = FakeEClusterIn(x)\n",
    "# print(\"Shape\", K.int_shape(x))\n",
    "x = e_clusters\n",
    "x = Conv1D(filters=1, kernel_size=5, strides=1, input_shape=node_embeddings.shape)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=5)(x)\n",
    "x = Conv1D(filters=1, kernel_size=5, strides=1)(x)\n",
    "x = MaxPooling1D(pool_size=5, strides=1)(x)\n",
    "print(\"Before removing last col\", K.int_shape(x))\n",
    "x = RemoveLastCol(x)\n",
    "print(\"after removing last col\", K.int_shape(x))\n",
    "entity_cluster_reps = Reshape([KG_EMBEDDING_DIM], name='entity_cluster_reps')(x)\n",
    "print(\"entity_cluster_reps(after reshape)\", K.int_shape(entity_cluster_reps))\n",
    "\n",
    "graph_input = Input(shape=(,), dtype='string', name='graph_input')                           \n",
    "x = FindCluster(x)\n",
    "graph = tf.keras.layers.StringLookup(vocabulary=cluster_names, output_mode='one_hot')(x)\n",
    "                               \n",
    "# attention over entities\n",
    "att_scores = DotProduct([entity_cluster_reps, graph])\n",
    "print(\"att_scores_entities\", K.int_shape(att_scores))\n",
    "# att_normalized = Activation('softmax',name='entity_attention')(att_scores)\n",
    "att_normalized = Softmax(axis=-1, name='entity_attention')(att_scores)\n",
    "print(\"att_normalized\", K.int_shape(att_normalized))\n",
    "the_entity = DotProduct([Transpose(entity_cluster_reps), att_normalized])\n",
    "print(\"the_entity\", K.int_shape(the_entity))\n",
    "\n",
    "lstm_hidden_and_entity = Concatenate(axis=0)([Transpose(main_lstm_out), the_entity])\n",
    "print(\"lstm_hidden_and_entity\", K.int_shape(lstm_hidden_and_entity))\n",
    "# input(\"continue?\")\n",
    "\n",
    "final_output = Dense(units=len(unique_labels), activation='softmax')(Transpose(lstm_hidden_and_entity))\n",
    "\n",
    "optimizer = Adam(lr=LEARNING_RATE, clipvalue=0.25)\n",
    "\n",
    "m = Model(inputs=[main_input,e_clusters,graph_input], outputs=final_output)\n",
    "\n",
    "m.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "_, tmpfn = tempfile.mkstemp()\n",
    "# Save the best model during validation and bail out of training early if we're not improving\n",
    "callbacks = [ModelCheckpoint(tmpfn, monitor='val_acc', save_best_only=True, save_weights_only=True)]\n",
    "\n",
    "m.summary()\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# plot_model(m, to_file='model.png')\n",
    "\n",
    "_, tmpfn = tempfile.mkstemp()\n",
    "# Save the best model during validation and bail out of training early if we're not improving\n",
    "callbacks = [ModelCheckpoint(tmpfn,monitor='val_acc', save_best_only=True, save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498510eb-6952-4d35-92cf-6e4efd3e7c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PREDICT WITH EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b290c8-e8a5-44e7-bf1b-0e5799d9cca9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 349/2418 [===>..........................] - ETA: 1:03:41 - loss: 4.4996 - acc: 0.0000e+ - ETA: 1:50 - loss: 7.3437 - acc: 0.0000e+00   - ETA: 1:49 - loss: 7.8418 - acc: 0.0000e+0 - ETA: 1:48 - loss: 7.4011 - acc: 0.0000e+0 - ETA: 1:47 - loss: 7.0167 - acc: 0.0000e+0 - ETA: 1:47 - loss: 6.8506 - acc: 0.0000e+0 - ETA: 1:46 - loss: 6.8360 - acc: 0.0000e+0 - ETA: 1:46 - loss: 6.9715 - acc: 0.0000e+0 - ETA: 1:46 - loss: 7.2541 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.4608 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.5667 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.5049 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.3822 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.3906 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.2569 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.1678 - acc: 0.0000e+0 - ETA: 1:45 - loss: 7.1228 - acc: 0.0000e+0 - ETA: 1:45 - loss: 6.9626 - acc: 0.0000e+0 - ETA: 1:44 - loss: 6.8294 - acc: 0.0000e+0 - ETA: 1:44 - loss: 6.7574 - acc: 0.0000e+0 - ETA: 1:44 - loss: 6.7398 - acc: 0.0122    - ETA: 1:44 - loss: 6.6293 - acc: 0.011 - ETA: 1:44 - loss: 6.5110 - acc: 0.011 - ETA: 1:44 - loss: 6.4289 - acc: 0.010 - ETA: 1:44 - loss: 6.4174 - acc: 0.010 - ETA: 1:44 - loss: 6.4139 - acc: 0.019 - ETA: 1:44 - loss: 6.3980 - acc: 0.018 - ETA: 1:44 - loss: 6.3357 - acc: 0.018 - ETA: 1:43 - loss: 6.2800 - acc: 0.017 - ETA: 1:43 - loss: 6.2110 - acc: 0.016 - ETA: 1:43 - loss: 6.1494 - acc: 0.016 - ETA: 1:43 - loss: 6.1320 - acc: 0.015 - ETA: 1:43 - loss: 6.1183 - acc: 0.015 - ETA: 1:43 - loss: 6.1100 - acc: 0.014 - ETA: 1:43 - loss: 6.0442 - acc: 0.014 - ETA: 1:43 - loss: 6.0207 - acc: 0.014 - ETA: 1:43 - loss: 5.9870 - acc: 0.013 - ETA: 1:43 - loss: 5.9378 - acc: 0.013 - ETA: 1:43 - loss: 5.8920 - acc: 0.019 - ETA: 1:42 - loss: 5.8380 - acc: 0.019 - ETA: 1:42 - loss: 5.8185 - acc: 0.018 - ETA: 1:42 - loss: 5.8091 - acc: 0.018 - ETA: 1:42 - loss: 5.7830 - acc: 0.017 - ETA: 1:42 - loss: 5.7492 - acc: 0.017 - ETA: 1:42 - loss: 5.7209 - acc: 0.016 - ETA: 1:42 - loss: 5.7242 - acc: 0.016 - ETA: 1:42 - loss: 5.7064 - acc: 0.016 - ETA: 1:42 - loss: 5.6843 - acc: 0.015 - ETA: 1:42 - loss: 5.6536 - acc: 0.015 - ETA: 1:42 - loss: 5.6195 - acc: 0.020 - ETA: 1:41 - loss: 5.5891 - acc: 0.019 - ETA: 1:41 - loss: 5.5771 - acc: 0.019 - ETA: 1:41 - loss: 5.5470 - acc: 0.019 - ETA: 1:41 - loss: 5.5330 - acc: 0.018 - ETA: 1:41 - loss: 5.5158 - acc: 0.018 - ETA: 1:41 - loss: 5.5163 - acc: 0.018 - ETA: 1:41 - loss: 5.5025 - acc: 0.017 - ETA: 1:41 - loss: 5.4765 - acc: 0.017 - ETA: 1:41 - loss: 5.4634 - acc: 0.017 - ETA: 1:41 - loss: 5.4503 - acc: 0.016 - ETA: 1:40 - loss: 5.4268 - acc: 0.016 - ETA: 1:40 - loss: 5.4203 - acc: 0.020 - ETA: 1:40 - loss: 5.4061 - acc: 0.020 - ETA: 1:40 - loss: 5.3915 - acc: 0.019 - ETA: 1:40 - loss: 5.3671 - acc: 0.019 - ETA: 1:40 - loss: 5.3603 - acc: 0.019 - ETA: 1:40 - loss: 5.3383 - acc: 0.018 - ETA: 1:40 - loss: 5.3274 - acc: 0.018 - ETA: 1:40 - loss: 5.3174 - acc: 0.018 - ETA: 1:40 - loss: 5.3057 - acc: 0.018 - ETA: 1:40 - loss: 5.2975 - acc: 0.017 - ETA: 1:39 - loss: 5.2776 - acc: 0.017 - ETA: 1:39 - loss: 5.2629 - acc: 0.017 - ETA: 1:39 - loss: 5.2516 - acc: 0.017 - ETA: 1:39 - loss: 5.2357 - acc: 0.016 - ETA: 1:39 - loss: 5.2206 - acc: 0.016 - ETA: 1:39 - loss: 5.2055 - acc: 0.016 - ETA: 1:39 - loss: 5.1965 - acc: 0.016 - ETA: 1:39 - loss: 5.1905 - acc: 0.015 - ETA: 1:39 - loss: 5.1705 - acc: 0.018 - ETA: 1:39 - loss: 5.1592 - acc: 0.018 - ETA: 1:39 - loss: 5.1421 - acc: 0.018 - ETA: 1:39 - loss: 5.1368 - acc: 0.018 - ETA: 1:39 - loss: 5.1304 - acc: 0.018 - ETA: 1:38 - loss: 5.1182 - acc: 0.017 - ETA: 1:38 - loss: 5.1089 - acc: 0.017 - ETA: 1:38 - loss: 5.1011 - acc: 0.017 - ETA: 1:38 - loss: 5.0882 - acc: 0.017 - ETA: 1:38 - loss: 5.0867 - acc: 0.016 - ETA: 1:38 - loss: 5.0809 - acc: 0.016 - ETA: 1:38 - loss: 5.0677 - acc: 0.019 - ETA: 1:38 - loss: 5.0560 - acc: 0.019 - ETA: 1:38 - loss: 5.0465 - acc: 0.018 - ETA: 1:38 - loss: 5.0373 - acc: 0.018 - ETA: 1:38 - loss: 5.0256 - acc: 0.021 - ETA: 1:37 - loss: 5.0199 - acc: 0.020 - ETA: 1:37 - loss: 5.0098 - acc: 0.020 - ETA: 1:37 - loss: 5.0023 - acc: 0.020 - ETA: 1:37 - loss: 4.9944 - acc: 0.020 - ETA: 1:37 - loss: 4.9868 - acc: 0.022 - ETA: 1:37 - loss: 4.9806 - acc: 0.022 - ETA: 1:37 - loss: 4.9782 - acc: 0.022 - ETA: 1:37 - loss: 4.9686 - acc: 0.024 - ETA: 1:37 - loss: 4.9649 - acc: 0.024 - ETA: 1:37 - loss: 4.9566 - acc: 0.023 - ETA: 1:37 - loss: 4.9484 - acc: 0.023 - ETA: 1:36 - loss: 4.9344 - acc: 0.028 - ETA: 1:36 - loss: 4.9230 - acc: 0.027 - ETA: 1:36 - loss: 4.9198 - acc: 0.027 - ETA: 1:36 - loss: 4.9153 - acc: 0.027 - ETA: 1:36 - loss: 4.9160 - acc: 0.027 - ETA: 1:36 - loss: 4.9101 - acc: 0.026 - ETA: 1:36 - loss: 4.9061 - acc: 0.026 - ETA: 1:36 - loss: 4.9007 - acc: 0.026 - ETA: 1:36 - loss: 4.8970 - acc: 0.028 - ETA: 1:36 - loss: 4.8940 - acc: 0.028 - ETA: 1:36 - loss: 4.8848 - acc: 0.027 - ETA: 1:35 - loss: 4.8813 - acc: 0.029 - ETA: 1:35 - loss: 4.8759 - acc: 0.029 - ETA: 1:35 - loss: 4.8707 - acc: 0.029 - ETA: 1:35 - loss: 4.8584 - acc: 0.031 - ETA: 1:35 - loss: 4.8554 - acc: 0.030 - ETA: 1:35 - loss: 4.8525 - acc: 0.030 - ETA: 1:35 - loss: 4.8470 - acc: 0.030 - ETA: 1:35 - loss: 4.8423 - acc: 0.030 - ETA: 1:35 - loss: 4.8364 - acc: 0.031 - ETA: 1:35 - loss: 4.8363 - acc: 0.031 - ETA: 1:35 - loss: 4.8303 - acc: 0.031 - ETA: 1:34 - loss: 4.8227 - acc: 0.031 - ETA: 1:34 - loss: 4.8168 - acc: 0.030 - ETA: 1:34 - loss: 4.8079 - acc: 0.032 - ETA: 1:34 - loss: 4.8026 - acc: 0.032 - ETA: 1:34 - loss: 4.7939 - acc: 0.034 - ETA: 1:34 - loss: 4.7879 - acc: 0.033 - ETA: 1:34 - loss: 4.7842 - acc: 0.033 - ETA: 1:34 - loss: 4.7837 - acc: 0.033 - ETA: 1:34 - loss: 4.7760 - acc: 0.033 - ETA: 1:34 - loss: 4.7658 - acc: 0.034 - ETA: 1:34 - loss: 4.7627 - acc: 0.034 - ETA: 1:33 - loss: 4.7582 - acc: 0.035 - ETA: 1:33 - loss: 4.7553 - acc: 0.035 - ETA: 1:33 - loss: 4.7536 - acc: 0.035 - ETA: 1:33 - loss: 4.7492 - acc: 0.035 - ETA: 1:33 - loss: 4.7448 - acc: 0.034 - ETA: 1:33 - loss: 4.7429 - acc: 0.034 - ETA: 1:33 - loss: 4.7399 - acc: 0.034 - ETA: 1:33 - loss: 4.7246 - acc: 0.034 - ETA: 1:33 - loss: 4.7135 - acc: 0.035 - ETA: 1:33 - loss: 4.7039 - acc: 0.037 - ETA: 1:33 - loss: 4.7003 - acc: 0.036 - ETA: 1:32 - loss: 4.6968 - acc: 0.036 - ETA: 1:32 - loss: 4.6945 - acc: 0.036 - ETA: 1:32 - loss: 4.6917 - acc: 0.036 - ETA: 1:32 - loss: 4.6911 - acc: 0.035 - ETA: 1:32 - loss: 4.6815 - acc: 0.037 - ETA: 1:32 - loss: 4.6791 - acc: 0.037 - ETA: 1:32 - loss: 4.6775 - acc: 0.036 - ETA: 1:32 - loss: 4.6786 - acc: 0.036 - ETA: 1:32 - loss: 4.6739 - acc: 0.036 - ETA: 1:32 - loss: 4.6710 - acc: 0.036 - ETA: 1:32 - loss: 4.6720 - acc: 0.035 - ETA: 1:31 - loss: 4.6690 - acc: 0.035 - ETA: 1:31 - loss: 4.6679 - acc: 0.035 - ETA: 1:31 - loss: 4.6644 - acc: 0.036 - ETA: 1:31 - loss: 4.6556 - acc: 0.038 - ETA: 1:31 - loss: 4.6560 - acc: 0.037 - ETA: 1:31 - loss: 4.6525 - acc: 0.037 - ETA: 1:31 - loss: 4.6470 - acc: 0.037 - ETA: 1:31 - loss: 4.6420 - acc: 0.037 - ETA: 1:31 - loss: 4.6391 - acc: 0.036 - ETA: 1:31 - loss: 4.6369 - acc: 0.036 - ETA: 1:31 - loss: 4.6372 - acc: 0.036 - ETA: 1:31 - loss: 4.6327 - acc: 0.037 - ETA: 1:30 - loss: 4.6319 - acc: 0.037 - ETA: 1:30 - loss: 4.6314 - acc: 0.0372"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "In  \u001b[0;34m[26]\u001b[0m:\nLine \u001b[0;34m8\u001b[0m:     callbacks=callbacks)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m, in \u001b[0;32mfit\u001b[0m:\nLine \u001b[0;34m1189\u001b[0m:  callbacks.on_train_batch_end(end_step, logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32mon_train_batch_end\u001b[0m:\nLine \u001b[0;34m435\u001b[0m:   \u001b[36mself\u001b[39;49;00m._call_batch_hook(ModeKeys.TRAIN, \u001b[33m'\u001b[39;49;00m\u001b[33mend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, batch, logs=logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32m_call_batch_hook\u001b[0m:\nLine \u001b[0;34m295\u001b[0m:   \u001b[36mself\u001b[39;49;00m._call_batch_end_hook(mode, batch, logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32m_call_batch_end_hook\u001b[0m:\nLine \u001b[0;34m315\u001b[0m:   \u001b[36mself\u001b[39;49;00m._call_batch_hook_helper(hook_name, batch, logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32m_call_batch_hook_helper\u001b[0m:\nLine \u001b[0;34m353\u001b[0m:   hook(batch, logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32mon_train_batch_end\u001b[0m:\nLine \u001b[0;34m1028\u001b[0m:  \u001b[36mself\u001b[39;49;00m._batch_update_progbar(batch, logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m, in \u001b[0;32m_batch_update_progbar\u001b[0m:\nLine \u001b[0;34m1100\u001b[0m:  logs = tf_utils.sync_to_numpy_or_python_type(logs)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/utils/tf_utils.py\u001b[0m, in \u001b[0;32msync_to_numpy_or_python_type\u001b[0m:\nLine \u001b[0;34m516\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m tf.nest.map_structure(_to_single_numpy_or_python_type, tensors)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m, in \u001b[0;32mmap_structure\u001b[0m:\nLine \u001b[0;34m869\u001b[0m:   structure[\u001b[34m0\u001b[39;49;00m], [func(*x) \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m entries],\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m, in \u001b[0;32m<listcomp>\u001b[0m:\nLine \u001b[0;34m869\u001b[0m:   structure[\u001b[34m0\u001b[39;49;00m], [func(*x) \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m entries],\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/keras/utils/tf_utils.py\u001b[0m, in \u001b[0;32m_to_single_numpy_or_python_type\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   x = t.numpy()\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m, in \u001b[0;32mnumpy\u001b[0m:\nLine \u001b[0;34m1094\u001b[0m:  maybe_arr = \u001b[36mself\u001b[39;49;00m._numpy()  \u001b[37m# pylint: disable=protected-access\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34m/home/cnytync/Dev/anaconda3/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m, in \u001b[0;32m_numpy\u001b[0m:\nLine \u001b[0;34m1060\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._numpy_internal()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: \n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "history = m.fit(x_train, y_train,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                validation_data=(x_val, y_val), \n",
    "                callbacks=callbacks)\n",
    "m.save('node2vec_lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c957190-3827-4b59-b51d-bf7279a41ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - ETA: 3:45 - loss: 3.1769e-04 - acc: 1.000 - ETA: 7s - loss: 2.7743 - acc: 0.6000      - ETA: 7s - loss: 1.5433 - acc: 0.777 - ETA: 7s - loss: 2.0892 - acc: 0.750 - ETA: 7s - loss: 2.4398 - acc: 0.710 - ETA: 7s - loss: 2.3416 - acc: 0.666 - ETA: 6s - loss: 2.2829 - acc: 0.655 - ETA: 6s - loss: 2.2964 - acc: 0.632 - ETA: 6s - loss: 2.2410 - acc: 0.628 - ETA: 6s - loss: 2.0426 - acc: 0.659 - ETA: 6s - loss: 1.9769 - acc: 0.653 - ETA: 6s - loss: 1.8795 - acc: 0.657 - ETA: 6s - loss: 1.8924 - acc: 0.644 - ETA: 6s - loss: 1.8377 - acc: 0.648 - ETA: 6s - loss: 1.8400 - acc: 0.644 - ETA: 6s - loss: 1.8671 - acc: 0.641 - ETA: 6s - loss: 1.8973 - acc: 0.645 - ETA: 5s - loss: 1.8080 - acc: 0.654 - ETA: 5s - loss: 1.8190 - acc: 0.646 - ETA: 5s - loss: 1.8212 - acc: 0.643 - ETA: 5s - loss: 1.8629 - acc: 0.636 - ETA: 5s - loss: 2.0627 - acc: 0.634 - ETA: 5s - loss: 2.0911 - acc: 0.633 - ETA: 5s - loss: 2.0960 - acc: 0.622 - ETA: 5s - loss: 2.0724 - acc: 0.621 - ETA: 5s - loss: 2.1147 - acc: 0.621 - ETA: 5s - loss: 2.0533 - acc: 0.627 - ETA: 5s - loss: 2.0496 - acc: 0.630 - ETA: 5s - loss: 2.0206 - acc: 0.636 - ETA: 5s - loss: 1.9644 - acc: 0.642 - ETA: 5s - loss: 1.9179 - acc: 0.647 - ETA: 5s - loss: 1.8881 - acc: 0.649 - ETA: 5s - loss: 1.9009 - acc: 0.647 - ETA: 5s - loss: 1.8930 - acc: 0.643 - ETA: 4s - loss: 1.8532 - acc: 0.647 - ETA: 4s - loss: 1.8444 - acc: 0.652 - ETA: 4s - loss: 1.8383 - acc: 0.653 - ETA: 4s - loss: 1.8144 - acc: 0.652 - ETA: 4s - loss: 1.7832 - acc: 0.658 - ETA: 4s - loss: 1.8224 - acc: 0.652 - ETA: 4s - loss: 1.8762 - acc: 0.650 - ETA: 4s - loss: 1.8546 - acc: 0.654 - ETA: 4s - loss: 1.8743 - acc: 0.648 - ETA: 4s - loss: 1.9150 - acc: 0.642 - ETA: 4s - loss: 1.8791 - acc: 0.646 - ETA: 4s - loss: 1.8492 - acc: 0.649 - ETA: 4s - loss: 1.8346 - acc: 0.650 - ETA: 4s - loss: 1.7976 - acc: 0.656 - ETA: 4s - loss: 1.7814 - acc: 0.659 - ETA: 4s - loss: 1.7900 - acc: 0.661 - ETA: 4s - loss: 1.7696 - acc: 0.664 - ETA: 3s - loss: 1.7643 - acc: 0.663 - ETA: 3s - loss: 1.7840 - acc: 0.656 - ETA: 3s - loss: 1.7750 - acc: 0.655 - ETA: 3s - loss: 1.7601 - acc: 0.656 - ETA: 3s - loss: 1.7292 - acc: 0.662 - ETA: 3s - loss: 1.7597 - acc: 0.657 - ETA: 3s - loss: 1.7455 - acc: 0.658 - ETA: 3s - loss: 1.7267 - acc: 0.660 - ETA: 3s - loss: 1.7069 - acc: 0.665 - ETA: 3s - loss: 1.7089 - acc: 0.663 - ETA: 3s - loss: 1.7085 - acc: 0.662 - ETA: 3s - loss: 1.7058 - acc: 0.661 - ETA: 3s - loss: 1.7087 - acc: 0.659 - ETA: 3s - loss: 1.7026 - acc: 0.656 - ETA: 3s - loss: 1.6924 - acc: 0.655 - ETA: 3s - loss: 1.6908 - acc: 0.655 - ETA: 3s - loss: 1.6915 - acc: 0.654 - ETA: 2s - loss: 1.6694 - acc: 0.657 - ETA: 2s - loss: 1.6945 - acc: 0.654 - ETA: 2s - loss: 1.6773 - acc: 0.656 - ETA: 2s - loss: 1.6773 - acc: 0.659 - ETA: 2s - loss: 1.6796 - acc: 0.657 - ETA: 2s - loss: 1.6964 - acc: 0.658 - ETA: 2s - loss: 1.7023 - acc: 0.658 - ETA: 2s - loss: 1.6961 - acc: 0.659 - ETA: 2s - loss: 1.6971 - acc: 0.657 - ETA: 2s - loss: 1.6799 - acc: 0.657 - ETA: 2s - loss: 1.6733 - acc: 0.659 - ETA: 2s - loss: 1.6662 - acc: 0.657 - ETA: 2s - loss: 1.6617 - acc: 0.659 - ETA: 2s - loss: 1.6872 - acc: 0.654 - ETA: 2s - loss: 1.6849 - acc: 0.655 - ETA: 2s - loss: 1.7451 - acc: 0.654 - ETA: 2s - loss: 1.7283 - acc: 0.656 - ETA: 2s - loss: 1.7203 - acc: 0.659 - ETA: 1s - loss: 1.7352 - acc: 0.656 - ETA: 1s - loss: 1.7283 - acc: 0.656 - ETA: 1s - loss: 1.7600 - acc: 0.653 - ETA: 1s - loss: 1.7443 - acc: 0.656 - ETA: 1s - loss: 1.7682 - acc: 0.654 - ETA: 1s - loss: 1.7648 - acc: 0.656 - ETA: 1s - loss: 1.7725 - acc: 0.656 - ETA: 1s - loss: 1.7646 - acc: 0.657 - ETA: 1s - loss: 1.7565 - acc: 0.656 - ETA: 1s - loss: 1.7701 - acc: 0.654 - ETA: 1s - loss: 1.7635 - acc: 0.653 - ETA: 1s - loss: 1.7549 - acc: 0.652 - ETA: 1s - loss: 1.7428 - acc: 0.654 - ETA: 1s - loss: 1.7372 - acc: 0.656 - ETA: 1s - loss: 1.7382 - acc: 0.657 - ETA: 1s - loss: 1.7306 - acc: 0.657 - ETA: 1s - loss: 1.7230 - acc: 0.658 - ETA: 1s - loss: 1.7270 - acc: 0.658 - ETA: 0s - loss: 1.7309 - acc: 0.656 - ETA: 0s - loss: 1.7201 - acc: 0.656 - ETA: 0s - loss: 1.7156 - acc: 0.656 - ETA: 0s - loss: 1.7117 - acc: 0.656 - ETA: 0s - loss: 1.7133 - acc: 0.657 - ETA: 0s - loss: 1.7123 - acc: 0.655 - ETA: 0s - loss: 1.7067 - acc: 0.655 - ETA: 0s - loss: 1.7015 - acc: 0.655 - ETA: 0s - loss: 1.6900 - acc: 0.657 - ETA: 0s - loss: 1.6793 - acc: 0.658 - ETA: 0s - loss: 1.6810 - acc: 0.658 - ETA: 0s - loss: 1.6737 - acc: 0.659 - ETA: 0s - loss: 1.6643 - acc: 0.661 - ETA: 0s - loss: 1.6643 - acc: 0.662 - ETA: 0s - loss: 1.6797 - acc: 0.659 - ETA: 0s - loss: 1.6699 - acc: 0.661 - ETA: 0s - loss: 1.6758 - acc: 0.660 - ETA: 0s - loss: 1.6778 - acc: 0.660 - 7s 11ms/step - loss: 1.6824 - acc: 0.6592\n",
      "Test loss / test accuracy = 1.6824 / 0.6592\n"
     ]
    }
   ],
   "source": [
    "# Restore the best found model during validation\n",
    "# m.load_weights(tmpfn)\n",
    "\n",
    "loss, acc = m.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc0dd40f-e908-4c93-ac5f-0f2a554d2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m.predict(x_test, batch_size=BATCH_SIZE, verbose=0,\n",
    "                  steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "453c14b0-12fd-4b07-a4e1-572a44cb6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_labels(results):\n",
    "    return [unique_labels[np.where(row==max(row))[0][0]] for row in results]\n",
    "\n",
    "result_labels = get_result_labels(preds)\n",
    "\n",
    "print('Accuracy score: %.2f' % accuracy_score(result_labels, y_str_test))\n",
    "print(classification_report(y_str_test, result_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

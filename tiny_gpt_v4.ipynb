{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2424ed0-4ebc-4c6d-bff7-beaffeea95d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow verions: 2.4.0\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras import ops\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph, IndexedArray\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stellargraph.mapper import AdjacencyPowerGenerator\n",
    "from stellargraph.layer import WatchYourStep\n",
    "from stellargraph import datasets, utils\n",
    "from tensorflow.keras import callbacks, optimizers, losses, metrics, regularizers, Model\n",
    "\n",
    "from stellargraph.mapper import KGTripleGenerator\n",
    "from stellargraph.layer import ComplEx\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from graph_visualization import GraphVisualization\n",
    "\n",
    "print(\"Tensorflow verions:\", tf.__version__)\n",
    "print('Available GPUs:', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b860e0-b6d6-49cc-8275-1d6b9beeb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Mask the upper half of the dot product matrix in self attention.\n",
    "    This prevents flow of information from future tokens to current token.\n",
    "    1's in the lower triangle, counting from the lower right corner.\n",
    "    \"\"\"\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, \"bool\")\n",
    "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ae20fa-e191-4b5f-92e7-7fd3d05d971b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50  # Only consider the top 20k words\n",
    "maxlen = 80  # Max sequence size\n",
    "batch_size = 128\n",
    "\n",
    "# The dataset contains each review in a separate text file\n",
    "# The text files are present in four different folders\n",
    "# Create a list all files\n",
    "filenames = []\n",
    "directories = [\n",
    "    \"gpt-dataset/custom-2.3\"\n",
    "]\n",
    "for dir in directories:\n",
    "    for f in os.listdir(dir):\n",
    "        filenames.append(os.path.join(dir, f))\n",
    "\n",
    "filenames = filenames[:10000]\n",
    "\n",
    "print(f\"{len(filenames)} files\")\n",
    "\n",
    "# Create a dataset from text files\n",
    "random.shuffle(filenames)\n",
    "text_ds = tf_data.TextLineDataset(filenames)\n",
    "text_ds = text_ds.shuffle(buffer_size=256)\n",
    "text_ds = text_ds.batch(batch_size)\n",
    "\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    \"\"\"Remove html line-break tags and handle punctuation\"\"\"\n",
    "    lowercased = tf_strings.lower(input_string)\n",
    "    stripped_html = tf_strings.regex_replace(lowercased, \"<br />\", \" \")\n",
    "    return tf_strings.regex_replace(stripped_html, f\"([{string.punctuation}])\", r\" \\1\")\n",
    "\n",
    "\n",
    "# Create a vectorization layer and adapt it to the text\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size - 1,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=maxlen + 1,\n",
    ")\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def count_occurences(text_ds):\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        # Custom text preprocessing\n",
    "        # For example, you can perform lowercasing, punctuation removal, etc.\n",
    "        return text.lower()\n",
    "    \n",
    "    # Preprocess the text data and convert it to a list\n",
    "    preprocessed_texts = [preprocess_text(str(text.numpy())) for text in text_ds]\n",
    "    # Initialize CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "    # Fit CountVectorizer on preprocessed text data and transform it into token counts\n",
    "    token_counts = vectorizer.fit_transform(preprocessed_texts)\n",
    "    # Get the vocabulary and token counts\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    counts = token_counts.toarray().sum(axis=0)\n",
    "    # Create a dictionary to store token counts\n",
    "    token_counts_dict = dict(zip(vocab, counts))\n",
    "\n",
    "    token_counts_dict = sorted(token_counts_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    print(token_counts_dict)\n",
    "\n",
    "# count_occurences(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b1ee954-6d7f-4e4e-af20-86800061973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'It is a musical instrument. It has 6 strings. What is this?'\n",
      " b'It is a musical instrument. It has 6 strings. What is this? Guitar.']\n"
     ]
    }
   ],
   "source": [
    "for text in text_ds:\n",
    "    print(str(text.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95d8db-170b-4421-b463-760d5355fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lm_inputs_labels(text):\n",
    "    \"\"\"\n",
    "    Shift word sequences by 1 position so that the target for position (i) is\n",
    "    word at position (i+1). The model will use all words up till position (i)\n",
    "    to predict the next word.\n",
    "    \"\"\"\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "\n",
    "    # zeros_column = tf.zeros_like(y[:, :1])  # Create a column of zeros with the same shape as the first column of y\n",
    "    # y = tf.concat([zeros_column, y], axis=1)  # Concatenate the zeros column with y along the column axis\n",
    "    \n",
    "    print('x',x)\n",
    "    print('y',y)\n",
    "    return x, y\n",
    "\n",
    "text_ds = text_ds.map(prepare_lm_inputs_labels, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "text_ds = text_ds.prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "96655133-7e51-43fd-a1a6-ac4abcc7d9ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_embedding_size = 10\n",
    "\n",
    "def node2vec(G):\n",
    "        walk_length = 100\n",
    "        rw = BiasedRandomWalk(G)\n",
    "        walks = rw.run(\n",
    "            nodes=G.nodes(),  # root nodes\n",
    "            length=walk_length,  # maximum length of a random walk\n",
    "            n=10,  # number of random walks per root node\n",
    "            p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "            q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "            weighted=False,  # for weighted random walks\n",
    "            seed=42,  # random seed fixed for reproducibility\n",
    "        )\n",
    "\n",
    "        model = Word2Vec(\n",
    "            walks,  vector_size=graph_embedding_size, window=5, min_count=0, sg=1, workers=1\n",
    "        )\n",
    "\n",
    "        return pd.DataFrame([(key, vector) for key,vector in zip(model.wv.index_to_key, model.wv.vectors)], columns=['node', 'embedding'])\n",
    "\n",
    "def get_graph():\n",
    "    nodes, edges, edge_types = [], [], []\n",
    "\n",
    "    for word in conceptnet_data['source'].unique():\n",
    "        nodes.append(word)\n",
    "\n",
    "    for word in conceptnet_data['target'].unique():\n",
    "        nodes.append(word) if word not in nodes else None\n",
    "\n",
    "    for index, row in conceptnet_data.iterrows():\n",
    "        edges.append({'source': row['source'], 'target': row['target']})\n",
    "        edge_types.append(row['label'])\n",
    "\n",
    "    graph = {'nodes':nodes, 'edges': edges, 'edge_types': edge_types}\n",
    "    \n",
    "    edges_ = pd.DataFrame({\n",
    "            'source': [e['source'] for e in graph['edges']],\n",
    "            'target': [e['target'] for e in graph['edges']],\n",
    "            'type': graph['edge_types']\n",
    "        })\n",
    "    \n",
    "    G = StellarGraph(IndexedArray(index=graph['nodes']), edges_, edge_type_column=\"type\")\n",
    "    \n",
    "    return graph, G\n",
    "\n",
    "def get_embeddings(G):\n",
    "    node_embeddings = complex_embeddings(G, conceptnet_data[['source','label','target']])\n",
    "        \n",
    "    return node_embeddings\n",
    "    \n",
    "graph, G = get_graph()\n",
    "node_embeddings = node2vec(G)\n",
    "\n",
    "tmp = []\n",
    "for i,word in enumerate(vocab):\n",
    "    lower_nodes = list(map(lambda k: k.lower(), node_embeddings['node']))\n",
    "    index = lower_nodes.index(word.lower()) if word.lower() in lower_nodes else -1\n",
    "    if index != -1:\n",
    "        tmp.append(node_embeddings.iloc[index][1])\n",
    "    else:\n",
    "        tmp.append(np.ones(graph_embedding_size) * -10)\n",
    "\n",
    "node_embeddings = np.array(tmp).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5c32efc5-96d2-44e4-8816-76e0efb7fae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "vis = GraphVisualization()\n",
    "for edge in graph['edges'][index:index+30]:\n",
    "    vis.addEdge(edge['source'], edge['target'])\n",
    "vis.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1a45ad26-9e27-4006-877c-2a722c625092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17827139169186743,\n",
       " 0.9923978840216339,\n",
       " 0.16621150077604804,\n",
       " 0.344310786941884)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptnet_data.loc[conceptnet_data['source'] == 'never']\n",
    "nodes = conceptnet_data['source'].unique()\n",
    "index_A = vocab.index('guitar')\n",
    "index_B = vocab.index('piano')\n",
    "index_C = vocab.index('lute')\n",
    "index_D = vocab.index('violin')\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(A,B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))\n",
    "\n",
    "A,B,C,D = node_embeddings[index_A], node_embeddings[index_B], node_embeddings[index_C], node_embeddings[index_D]\n",
    "cosine_sim(A,B), cosine_sim(A,C), cosine_sim(B,C), cosine_sim(B,D)\n",
    "# index_never, index_always, index_little\n",
    "# A,B,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c8823209-4d3f-4a41-978a-3de62eabef51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [(word, emb) for word, emb in zip(vocab, node_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "643dd0da-acfd-4966-aa28-9841f6395271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]  # Modified line\n",
    "        positions = tf.range(0, maxlen, 1)  # Modified line\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7146048c-63e5-4c02-956a-9990a8c75fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbedding(layers.Layer):\n",
    "    def __init__(self, node_embed_dim, node_embeddings):\n",
    "        super().__init__()\n",
    "        self.node_embeddings = tf.constant(node_embeddings, dtype=tf.float32)\n",
    "        self.node_embed_dim = node_embed_dim\n",
    "        self.dense = layers.Dense(node_embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "         # Reshape x to add a new dimension for embedding\n",
    "        node_indices = tf.cast(tf.math.round(x), tf.int32)\n",
    "        node_emb = tf.gather(self.node_embeddings, node_indices)\n",
    "        node_emb = self.dense(node_emb)  # Apply dense layer to each token embedding\n",
    "        return node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ffa7b441-9e76-41c3-af92-55bc9c7b1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate text from a trained model.\n",
    "    1. Feed some starting prompt to the model\n",
    "    2. Predict probabilities for the next token\n",
    "    3. Sample the next token and add it to the next input\n",
    "\n",
    "    Arguments:\n",
    "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
    "        start_tokens: List of integers, the token indices for the starting prompt.\n",
    "        index_to_word: List of strings, obtained from the TextVectorization layer.\n",
    "        top_k: Integer, sample from the `top_k` token predictions.\n",
    "        print_every: Integer, print after this many epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, max_tokens, start_tokens, index_to_word, model = None, top_k=10, print_every=1\n",
    "    ):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.start_tokens = start_tokens\n",
    "        self.index_to_word = index_to_word\n",
    "        self.print_every = print_every\n",
    "        self.k = top_k\n",
    "        if model: self.model = model\n",
    "        self.yes_count = 0\n",
    "        self.no_count = 0\n",
    "        self.activation_outputs = []\n",
    "        self.gradients = []\n",
    "\n",
    "    def sample_from(self, logits):\n",
    "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
    "        indices = tf.convert_to_tensor(indices, dtype=tf.int32)\n",
    "        preds = tf.keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = tf.convert_to_tensor(preds, dtype=tf.float32)\n",
    "  \n",
    "        # Reshape logits to a matrix\n",
    "        logits_matrix = tf.reshape(logits, (1, -1))\n",
    "   \n",
    "        # Sample from the softmax probabilities\n",
    "        sampled_index = tf.random.categorical(tf.math.log(preds)[tf.newaxis, :], num_samples=1)\n",
    "\n",
    "        # Return the sampled index\n",
    "        return indices[sampled_index[0, 0]]\n",
    "\n",
    "    def detokenize(self, number):\n",
    "        return self.index_to_word[number] if number < len(self.index_to_word) else '---'\n",
    "\n",
    "    def generate_token(self, _start_tokens, tokens_generated):\n",
    "        pad_len = maxlen - len(_start_tokens)\n",
    "        sample_index = len(_start_tokens) - 1\n",
    "        if pad_len < 0:\n",
    "            x = _start_tokens[:maxlen]\n",
    "            sample_index = maxlen - 1\n",
    "        elif pad_len > 0:\n",
    "            x = _start_tokens + [0] * pad_len\n",
    "        else:\n",
    "            x = _start_tokens\n",
    "        x = np.array([x])\n",
    "        y = self.model.predict(x, verbose=0)\n",
    "        sample_token = self.sample_from(y[0][sample_index])\n",
    "        tokens_generated.append(sample_token)\n",
    "        _start_tokens.append(sample_token)\n",
    "        num_tokens_generated = len(tokens_generated)\n",
    "\n",
    "        return _start_tokens, tokens_generated, num_tokens_generated, y\n",
    "\n",
    "    def get_generated_text(self, tokens_generated):\n",
    "        return \" \".join(\n",
    "            [self.detokenize(_) for _ in tokens_generated])\n",
    "        \n",
    "    def get_text(self, tokens_generated):\n",
    "        return \" \".join(\n",
    "            [self.detokenize(_) for _ in self.start_tokens + tokens_generated])\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _start_tokens = [_ for _ in self.start_tokens]\n",
    "        if (epoch + 1) % self.print_every != 0:\n",
    "            return\n",
    "        num_tokens_generated = 0\n",
    "        tokens_generated = []\n",
    "        raw_outputs = []\n",
    "        while num_tokens_generated <= self.max_tokens:\n",
    "            _start_tokens, tokens_generated, num_tokens_generated, raw_output = self.generate_token(_start_tokens, tokens_generated)\n",
    "            raw_outputs.append(raw_output)\n",
    "            \n",
    "        txt = self.get_text(tokens_generated)\n",
    "        print(f\"generated text:\\n{txt}\\n\")\n",
    "\n",
    "        self.yes_count += 1 if 'yes' in txt else 0\n",
    "        self.no_count += 1 if 'no' in txt else 0\n",
    "\n",
    "        return txt, raw_outputs\n",
    "    \n",
    "    def generate(self):\n",
    "        return self.on_epoc_end(1)\n",
    "\n",
    "# Tokenize starting prompt\n",
    "word_to_index = {}\n",
    "for index, word in enumerate(vocab):\n",
    "    word_to_index[word] = index\n",
    "\n",
    "def callback(start_prompt, model=None, top_k=10):\n",
    "    start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n",
    "    num_tokens_generated = 10\n",
    "    return TextGenerator(num_tokens_generated, start_tokens, vocab, top_k=top_k) if not model else TextGenerator(num_tokens_generated, start_tokens, vocab, model, top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "55a846ea-5ac4-4567-87ec-f8fa941def77",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "feed_forward_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "def create_model():\n",
    "    inputs = layers.Input(shape=(maxlen,), dtype=\"float32\")\n",
    "    \n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
    "    x = transformer_block(x)\n",
    "\n",
    "    outputs_1 = layers.Dense(vocab_size, name='text_output')(x)\n",
    "\n",
    "    node_embedding_layer = NodeEmbedding(embed_dim, node_embeddings)\n",
    "    x2 = node_embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, feed_forward_dim)\n",
    "    x2 = transformer_block(x2)\n",
    "\n",
    "    outputs_2 = layers.Dense(vocab_size, name='graph_output')(x2)\n",
    "\n",
    "    # Concatenate outputs of both branches\n",
    "    outputs = layers.Average()([outputs_1, outputs_2])\n",
    "\n",
    "    # outputs = outputs_1\n",
    "\n",
    "    # Softmax layer\n",
    "    # softmax_output = layers.Softmax()(outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[outputs])\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=[loss_fn, None],\n",
    "    )  # No loss and optimization based on word embeddings from transformer block\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d8a89464-95aa-4f85-a45b-16177b35e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_and_position_embedding_13 (None, 80, 128)      16640       input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "node_embedding_13 (NodeEmbeddin (None, 80, 128)      1408        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_26 (Transform (None, 80, 128)      165504      token_and_position_embedding_13[0\n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_27 (Transform (None, 80, 128)      165504      node_embedding_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "text_output (Dense)             (None, 80, 50)       6450        transformer_block_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "graph_output (Dense)            (None, 80, 50)       6450        transformer_block_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "average_3 (Average)             (None, 80, 50)       0           text_output[0][0]                \n",
      "                                                                 graph_output[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 361,956\n",
      "Trainable params: 361,956\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "bee3dc5a-315b-4583-ade5-551edbc6c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_callback = callback(\"guitar is similar to \", model, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1cce73d0-6f9a-4586-bc1c-b9087b379b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.5361\n",
      "generated text:\n",
      "guitar is similar to ---    --- clarinet   .  ---\n",
      "\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8583\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5009\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3422\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3254\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3127\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2824\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2440\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2016\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1621\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1346\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1191\n",
      "generated text:\n",
      "guitar is similar to           \n",
      "\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1084\n",
      "generated text:\n",
      "guitar is similar to to          \n",
      "\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1028\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0945\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0878\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0859\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0825\n",
      "generated text:\n",
      "guitar is similar to to to .        \n",
      "\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0810\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0786\n",
      "generated text:\n",
      "guitar is similar to to .         \n",
      "\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0759\n",
      "generated text:\n",
      "guitar is similar to not similar .        \n",
      "\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0736\n",
      "generated text:\n",
      "guitar is similar to to to .        \n",
      "\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0704\n",
      "generated text:\n",
      "guitar is similar to to to         \n",
      "\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0688\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0661\n",
      "generated text:\n",
      "guitar is similar to to to .        \n",
      "\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0646\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0644\n",
      "generated text:\n",
      "guitar is similar to to to         \n",
      "\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0614\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0593\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0576\n",
      "generated text:\n",
      "guitar is similar to to to         \n",
      "\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0564\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0558\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0541\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0528\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0522\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0507\n",
      "generated text:\n",
      "guitar is similar to to guitar .        \n",
      "\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0498\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0505\n",
      "generated text:\n",
      "guitar is similar to to piano .        \n",
      "\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0480\n",
      "generated text:\n",
      "guitar is similar to to guitar .        \n",
      "\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0483\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0468\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0480\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0460\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0463\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0466\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0461\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0442\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0452\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0444\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0437\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0442\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0424\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0445\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0432\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0431\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0428\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0428\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0422\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0412\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0418\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0403\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0406\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0416\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0404\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0399\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0396\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0406\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0403\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0406\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0400\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0400\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0394\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0386\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0392\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0387\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0380\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0395\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0386\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0386\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0392\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0385\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0384\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0371\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0389\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0385\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0380\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0382\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0383\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0382\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0368\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0377\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0373\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0377\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0376\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0377\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0375\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0371\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0363\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0377\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0368\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0363\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0372\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0364\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0371\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0359\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0360\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0381\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0365\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0363\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0377\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0365\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0370\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0365\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0359\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0369\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0367\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0366\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0351\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0363\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0353\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0360\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0357\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0373\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0363\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0353\n",
      "generated text:\n",
      "guitar is similar to clarinet .         \n",
      "\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0357\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0353\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0350\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0356\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0347\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0348\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0358\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0340\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0350\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0350\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0336\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0340\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0345\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0354\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0335\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0339\n",
      "generated text:\n",
      "guitar is similar to guitar .         \n",
      "\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0340\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0332\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0341\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0327\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0327\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0329\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0314\n",
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0325\n",
      "generated text:\n",
      "guitar is similar to piano .         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(text_ds, verbose=1, epochs=150, callbacks=[text_gen_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "88397d80-910e-4a43-9c36-219fd316ffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 127)"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_gen_callback.yes_count, text_gen_callback.no_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1c4a5f37-eb02-402f-a397-98915cf43202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:\n",
      "guitar is similar to lute .         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = callback('guitar is similar to ', model, 1)\n",
    "output = generator.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9b060e47-a3d2-439a-9a90-025a25eb42d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('text_output').output)\n",
    "graph_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('graph_output').output)\n",
    "text = 'guitar is similar to '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7aac840f-0bf1-4142-aaea-9b7bfff8b7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:\n",
      "guitar is similar to viola .         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = callback(text, text_model, 1)\n",
    "output = generator.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "4b3269d6-79df-4d12-949f-acba6f191642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:\n",
      "guitar is similar to           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = callback(text, graph_model, 1)\n",
    "output = generator.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "1d546c53-a2fd-4e3d-a9ed-a35bf2747f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = text_gen_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "38a17fcb-d0d3-4944-9852-5cfa23c1eafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.0852995 , -2.1351993 ,  3.9451284 ,  4.273572  , -2.2253819 ,\n",
       "        -0.90423506,  3.4084606 ,  2.3410375 ,  3.4026048 ,  2.561064  ,\n",
       "         2.1187518 ,  2.1935887 ,  2.0319324 , -0.19848181,  1.6990896 ,\n",
       "         0.9556687 ,  0.72840387, -2.8963487 , -1.785921  , -4.008631  ,\n",
       "        -2.9635823 , -2.016038  , -2.280281  , -2.2860997 , -2.390443  ,\n",
       "        -1.726803  , -2.2424977 , -3.6825337 , -1.8128119 , -3.5176842 ,\n",
       "        -2.1452487 , -2.1806    , -1.5033053 , -3.7006183 , -3.474283  ,\n",
       "        -1.7460822 , -2.0837238 , -2.2618098 , -1.797773  , -3.1555114 ,\n",
       "        -3.4014728 , -3.6229672 , -2.2904289 , -2.5505588 , -2.1384702 ,\n",
       "        -3.761304  , -2.3024962 , -2.3601925 , -0.77420133, -3.1423674 ],\n",
       "       dtype=float32),\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       " 9.0852995,\n",
       " '',\n",
       " [<tf.Tensor: shape=(), dtype=int32, numpy=0>],\n",
       " 'guitar is similar to ')"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_tokens, tokens_generated, num_tokens_generated, raw_output = generator.generate_token([_ for _ in generator.start_tokens], [])\n",
    "index = len(generator.start_tokens) - 1\n",
    "raw_output[0][index], tf.argmax(raw_output[0][index]), np.max(raw_output[0][index]), vocab[tf.argmax(raw_output[0][index])], tokens_generated, generator.get_text(tokens_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4895cfc9-be92-48b2-ba1c-2269585ab8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     index      value\n",
       " 0        0  10.567556\n",
       " 1       18   4.778914\n",
       " 2        3   3.885499\n",
       " 3       26   3.815091\n",
       " 4       16   3.443519\n",
       " ..     ...        ...\n",
       " 295    243  -7.266131\n",
       " 296    142  -7.344137\n",
       " 297    246  -7.488056\n",
       " 298    237  -7.561741\n",
       " 299     37  -8.187204\n",
       " \n",
       " [300 rows x 2 columns],\n",
       " 'banjo')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indexes = np.argsort(raw_output[0][index])[::-1]\n",
    "sorted = raw_output[0][index][sorted_indexes]\n",
    "df = pd.DataFrame({'index': sorted_indexes, 'value': sorted})\n",
    "df, vocab[df.iloc[1]['index'].astype('int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aad146-54d2-414b-a5b8-46fdef28d854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-37",
   "language": "python",
   "name": "tf-37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
